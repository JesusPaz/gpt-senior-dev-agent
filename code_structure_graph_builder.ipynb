{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d8a1721-02df-4e79-b9b7-083bc43afa30",
   "metadata": {},
   "source": [
    "# üß† GPT now understands my repo like a senior dev ‚Äì here's how\n",
    "\n",
    "This notebook is an end-to-end reproduction and reinterpretation of the **CodeRAG** framework (see [paper](https://arxiv.org/pdf/2504.10046)), adapted to run locally on your own codebase.\n",
    "\n",
    "We want to give GPT (or any LLM) the ability to:\n",
    "- Parse and **understand your entire repo**\n",
    "- Retrieve and reason over related code\n",
    "- Answer questions like a senior developer would ‚Äî with **zero fine-tuning**\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Goal of this experiment\n",
    "\n",
    "Our objective is to build a **code-aware assistant** using a combination of:\n",
    "\n",
    "- üîç **Tree-sitter** to parse and structure the codebase\n",
    "- üß† **LLMs** to describe each function or class (aka \"requirements\")\n",
    "- üï∏Ô∏è **Code graphs** to represent dependencies (calls, imports, etc)\n",
    "- üß≠ **Agentic reasoning** to let the LLM query and retrieve context dynamically\n",
    "- ‚ö° **RAG (Retrieval-Augmented Generation)** to reduce hallucinations and give smarter answers\n",
    "\n",
    "The end result is a local-first, fully transparent, and extensible RAG pipeline tailored for your own project.\n",
    "\n",
    "---\n",
    "\n",
    "## üß™ Inspired by CodeRAG (What we're replicating)\n",
    "\n",
    "From the CodeRAG paper (April 2025), we aim to recreate the following innovations:\n",
    "\n",
    "1. **Requirement Graph**  \n",
    "   A graph where each node is a *natural language description* of a function or class. Edges represent semantic similarity or parent-child relations.\n",
    "\n",
    "2. **DS-Code Graph**  \n",
    "   A code graph that encodes structural dependencies like:\n",
    "   - function calls\n",
    "   - class inheritance\n",
    "   - file/module containment\n",
    "   - semantic similarity (via embeddings)\n",
    "\n",
    "3. **BiGraph Mapping**  \n",
    "   Links between requirements and code elements ‚Äî allowing retrieval of relevant code given a high-level prompt.\n",
    "\n",
    "4. **Agentic Reasoning**  \n",
    "   An LLM-driven reasoning loop that dynamically:\n",
    "   - queries the graph\n",
    "   - follows dependencies\n",
    "   - does web search if needed\n",
    "   - formats and tests generated code\n",
    "\n",
    "---\n",
    "\n",
    "## ü™ú Pipeline Overview (what this notebook covers)\n",
    "\n",
    "| Step | Description |\n",
    "|------|-------------|\n",
    "| ‚úÖ 1. Parse your local repo using Tree-sitter |\n",
    "| ‚úÖ 2. Extract all functions and classes |\n",
    "| ‚úÖ 3. Generate descriptions for each (via LLM) |\n",
    "| ‚úÖ 4. Build the **Requirement Graph** |\n",
    "| ‚úÖ 5. Build the **DS-Code Graph** |\n",
    "| ‚úÖ 6. Link both graphs into a BiGraph |\n",
    "| ‚úÖ 7. Implement a simple **agentic loop** using ReAct |\n",
    "| ‚úÖ 8. Let GPT answer deep questions about your code (with full context) |\n",
    "\n",
    "---\n",
    "\n",
    "## üß∞ Tech Stack\n",
    "\n",
    "| Component        | Tool                            |\n",
    "|------------------|---------------------------------|\n",
    "| Parsing          | `tree-sitter-language-pack`     |\n",
    "| Description gen. | OpenAI / DeepSeek-V2.5          |\n",
    "| Graph storage    | Neo4j                           |\n",
    "| Semantic sim.    | HuggingFace Transformers        |\n",
    "| Reasoning agent  | Custom ReAct (or LangChain)     |\n",
    "| Validation       | `black`, `pytest`, `mypy`       |\n",
    "\n",
    "---\n",
    "\n",
    "## üîó References & Credits\n",
    "\n",
    "- [CodeRAG: Supportive Code Retrieval on Bigraph for Real-World Code Generation](https://arxiv.org/pdf/2504.10046)\n",
    "- [Self-RAG (Asai et al., 2023)](https://arxiv.org/pdf/2307.05068)\n",
    "- [DRAGIN: Dynamic RAG for real-time needs](https://arxiv.org/pdf/2501.13742)\n",
    "- [CodeRAG benchmark (June 2024)](https://arxiv.org/pdf/2406.14497)\n",
    "\n",
    "---\n",
    "\n",
    "üëâ Let‚Äôs get started by parsing the repo with Tree-sitter..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bbbf10-7219-41aa-ab35-ae06a06fb5f8",
   "metadata": {},
   "source": [
    "## üì¶ Install dependencies\n",
    "\n",
    "We‚Äôll begin by installing the `tree-sitter-language-pack` Python library, which provides precompiled Tree-sitter grammars for popular languages ‚Äî including Python.\n",
    "\n",
    "This saves us from having to manually clone grammars or compile `.so` libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5baed20f-b420-4afd-87a2-819ed4bf6c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tree-sitter-language-pack\n",
      "  Downloading tree_sitter_language_pack-0.8.0-cp39-abi3-macosx_10_13_universal2.whl.metadata (17 kB)\n",
      "Requirement already satisfied: tree-sitter>=0.23.2 in /opt/anaconda3/lib/python3.12/site-packages (from tree-sitter-language-pack) (0.24.0)\n",
      "Collecting tree-sitter-c-sharp>=0.23.1 (from tree-sitter-language-pack)\n",
      "  Downloading tree_sitter_c_sharp-0.23.1-cp39-abi3-macosx_11_0_arm64.whl.metadata (2.7 kB)\n",
      "Collecting tree-sitter-embedded-template>=0.23.2 (from tree-sitter-language-pack)\n",
      "  Downloading tree_sitter_embedded_template-0.23.2-cp39-abi3-macosx_11_0_arm64.whl.metadata (2.2 kB)\n",
      "Collecting tree-sitter-yaml>=0.7.0 (from tree-sitter-language-pack)\n",
      "  Downloading tree_sitter_yaml-0.7.1-cp310-abi3-macosx_11_0_arm64.whl.metadata (1.8 kB)\n",
      "Downloading tree_sitter_language_pack-0.8.0-cp39-abi3-macosx_10_13_universal2.whl (28.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m28.6/28.6 MB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading tree_sitter_c_sharp-0.23.1-cp39-abi3-macosx_11_0_arm64.whl (419 kB)\n",
      "Downloading tree_sitter_embedded_template-0.23.2-cp39-abi3-macosx_11_0_arm64.whl (10 kB)\n",
      "Downloading tree_sitter_yaml-0.7.1-cp310-abi3-macosx_11_0_arm64.whl (45 kB)\n",
      "Installing collected packages: tree-sitter-yaml, tree-sitter-embedded-template, tree-sitter-c-sharp, tree-sitter-language-pack\n",
      "Successfully installed tree-sitter-c-sharp-0.23.1 tree-sitter-embedded-template-0.23.2 tree-sitter-language-pack-0.8.0 tree-sitter-yaml-0.7.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tree-sitter-language-pack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55627cc9-16a1-4989-8851-c739c9586824",
   "metadata": {},
   "source": [
    "## üß™ Parse a test string with Tree-sitter\n",
    "\n",
    "Let's load the Python parser and run Tree-sitter on a simple test snippet to confirm everything is working.\n",
    "\n",
    "We also define a small `dump()` helper function to pretty-print the AST (abstract syntax tree) node structure.\n",
    "\n",
    "This will help us verify that Tree-sitter is correctly parsing the function and its components (name, parameters, body, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a213375-9fa7-48bc-be27-0683df2f6027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module: def foo(): pass\n",
      "  function_definition: def foo(): pass\n",
      "    identifier: foo\n",
      "    parameters: ()\n",
      "    block: pass\n",
      "      pass_statement: pass\n"
     ]
    }
   ],
   "source": [
    "from tree_sitter_language_pack import get_parser\n",
    "\n",
    "parser = get_parser(\"python\")\n",
    "tree = parser.parse(b\"def foo(): pass\")\n",
    "\n",
    "def dump(node, indent=0):\n",
    "    print(\"  \" * indent + f\"{node.type}: {node.text.decode('utf-8')}\")\n",
    "    for child in node.named_children:\n",
    "        dump(child, indent + 1)\n",
    "\n",
    "root = parser.parse(b\"def foo(): pass\").root_node\n",
    "dump(root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1934e129-9a69-4bd9-bbea-91e73a1261f7",
   "metadata": {},
   "source": [
    "## üìÇ Parse all Python files in the repo\n",
    "\n",
    "Now that Tree-sitter is working, let‚Äôs walk through the entire local repo and extract all `function_definition` and `class_definition` nodes.\n",
    "\n",
    "For each one, we‚Äôll collect:\n",
    "\n",
    "- Type (`function` or `class`)\n",
    "- Name\n",
    "- Start and end line\n",
    "- File path\n",
    "\n",
    "This structured data will help us build the code graph later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e543255f-8a51-48eb-9f8a-aa9cd536129d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tree_sitter_language_pack import get_parser\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# Setup\n",
    "parser = get_parser(\"python\")\n",
    "REPO_ROOT = Path(\".\").resolve()\n",
    "\n",
    "# Extract function/class nodes\n",
    "def extract_code_elements(source_code: str, file_path: str):\n",
    "    tree = parser.parse(bytes(source_code, \"utf-8\"))\n",
    "    root = tree.root_node\n",
    "    elements = []\n",
    "\n",
    "    def visit(node):\n",
    "        if node.type in (\"function_definition\", \"class_definition\"):\n",
    "            name_node = node.child_by_field_name(\"name\")\n",
    "            name = name_node.text.decode(\"utf-8\") if name_node else \"<anonymous>\"\n",
    "            elements.append({\n",
    "                \"type\": node.type,\n",
    "                \"name\": name,\n",
    "                \"start_line\": node.start_point[0] + 1,\n",
    "                \"end_line\": node.end_point[0] + 1,\n",
    "                \"file\": str(file_path)\n",
    "            })\n",
    "        for child in node.named_children:\n",
    "            visit(child)\n",
    "\n",
    "    visit(root)\n",
    "    return elements\n",
    "\n",
    "# Walk through repo\n",
    "all_elements = []\n",
    "for py_file in REPO_ROOT.rglob(\"*.py\"):\n",
    "    try:\n",
    "        code = py_file.read_text(encoding=\"utf-8\")\n",
    "        extracted = extract_code_elements(code, py_file.relative_to(REPO_ROOT))\n",
    "        all_elements.extend(extracted)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Failed to parse {py_file}: {e}\")\n",
    "\n",
    "# Save results\n",
    "with open(\"code_elements.json\", \"w\") as f:\n",
    "    json.dump(all_elements, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56dd4ee-d962-4858-8615-434882ef0bbb",
   "metadata": {},
   "source": [
    "## üßæ Requirement Descriptions (Docstrings)\n",
    "\n",
    "In this project, we assume that each function and class in the codebase already includes a properly written **docstring** that describes its purpose, inputs, and outputs.\n",
    "\n",
    "This serves as the \"requirement\" we need for building the **Requirement Graph** in the next step.\n",
    "\n",
    "> ‚ö†Ô∏è If the codebase lacks docstrings or uses inconsistent formatting, you would need to generate these descriptions using a language model (e.g. GPT-4 or DeepSeek) based on the raw source code.\n",
    "\n",
    "Since our current dataset is clean and well-documented, we‚Äôll skip this step and move directly to extracting docstrings from the parsed code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116bbb04-2696-45c5-bd83-177a37352973",
   "metadata": {},
   "source": [
    "### üîÑ Extract docstrings with Python `ast`\n",
    "\n",
    "Tree-sitter gives us positions, calls, etc.  \n",
    "For docstrings the built-in `ast` module is simpler and bullet-proof.\n",
    "This cell parses each file twice:\n",
    "\n",
    "* Tree-sitter ‚Üí start/end lines, names, calls (as before)  \n",
    "* AST ‚Üí exact docstring for every func/class  \n",
    "\n",
    "The result is `code_elements_with_docstrings.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8539ed5f-4257-4ef8-8fa5-fe03eb07acae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ saved 102 elements with docstrings\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>docstring</th>\n",
       "      <th>start_line</th>\n",
       "      <th>end_line</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>function_definition</td>\n",
       "      <td>root</td>\n",
       "      <td>Root endpoint to verify the API is running.</td>\n",
       "      <td>47</td>\n",
       "      <td>51</td>\n",
       "      <td>app/main.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>function_definition</td>\n",
       "      <td>health_check</td>\n",
       "      <td>Health check endpoint to verify the API is run...</td>\n",
       "      <td>54</td>\n",
       "      <td>58</td>\n",
       "      <td>app/main.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>function_definition</td>\n",
       "      <td>load_config</td>\n",
       "      <td>Load configuration from environment variables....</td>\n",
       "      <td>13</td>\n",
       "      <td>45</td>\n",
       "      <td>app/core/config.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>class_definition</td>\n",
       "      <td>Database</td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>1438</td>\n",
       "      <td>app/core/database.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>function_definition</td>\n",
       "      <td>__init__</td>\n",
       "      <td>Initialize the database connection with the gi...</td>\n",
       "      <td>15</td>\n",
       "      <td>32</td>\n",
       "      <td>app/core/database.py</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  type          name  \\\n",
       "0  function_definition          root   \n",
       "1  function_definition  health_check   \n",
       "2  function_definition   load_config   \n",
       "3     class_definition      Database   \n",
       "4  function_definition      __init__   \n",
       "\n",
       "                                           docstring  start_line  end_line  \\\n",
       "0        Root endpoint to verify the API is running.          47        51   \n",
       "1  Health check endpoint to verify the API is run...          54        58   \n",
       "2  Load configuration from environment variables....          13        45   \n",
       "3                                                             14      1438   \n",
       "4  Initialize the database connection with the gi...          15        32   \n",
       "\n",
       "                   file  \n",
       "0           app/main.py  \n",
       "1           app/main.py  \n",
       "2    app/core/config.py  \n",
       "3  app/core/database.py  \n",
       "4  app/core/database.py  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast, json, pandas as pd\n",
    "from tree_sitter_language_pack import get_parser\n",
    "from pathlib import Path\n",
    "\n",
    "parser = get_parser(\"python\")\n",
    "ROOT   = Path(\".\").resolve()\n",
    "out    = []\n",
    "\n",
    "def ts_name_and_span(src: str):\n",
    "    \"\"\"Return dict {name,start,end} for every function/class via Tree-sitter.\"\"\"\n",
    "    tree = parser.parse(src.encode())\n",
    "    root = tree.root_node\n",
    "    res  = []\n",
    "\n",
    "    def walk(node):\n",
    "        if node.type in (\"function_definition\", \"class_definition\"):\n",
    "            name = node.child_by_field_name(\"name\").text.decode()\n",
    "            res.append((name, node.start_point[0]+1, node.end_point[0]+1))\n",
    "        for c in node.named_children:\n",
    "            walk(c)\n",
    "    walk(root)\n",
    "    return res\n",
    "\n",
    "for py in ROOT.rglob(\"*.py\"):\n",
    "    code = py.read_text(encoding=\"utf-8\")\n",
    "    # 1Ô∏è‚É£ positions with tree-sitter\n",
    "    spans = ts_name_and_span(code)\n",
    "    # 2Ô∏è‚É£ docstrings with ast\n",
    "    module = ast.parse(code, filename=str(py))\n",
    "    for node in ast.walk(module):\n",
    "        if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef)):\n",
    "            doc = ast.get_docstring(node) or \"\"\n",
    "            name = node.name\n",
    "            # match span (name is unique inside file)\n",
    "            start, end = next((s,e) for n,s,e in spans if n == name)\n",
    "            out.append({\n",
    "                \"type\": \"class_definition\" if isinstance(node, ast.ClassDef) else \"function_definition\",\n",
    "                \"name\": name,\n",
    "                \"docstring\": doc,\n",
    "                \"start_line\": start,\n",
    "                \"end_line\": end,\n",
    "                \"file\": str(py.relative_to(ROOT))\n",
    "            })\n",
    "\n",
    "with open(\"code_elements_with_docstrings.json\", \"w\") as f:\n",
    "    json.dump(out, f, indent=2)\n",
    "print(\"‚úÖ saved\", len(out), \"elements with docstrings\")\n",
    "pd.DataFrame(out).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828125fc-230b-441e-9f10-29b7d1a57f08",
   "metadata": {},
   "source": [
    "## üì• Load elements (docstrings included)\n",
    "\n",
    "This cell reads **`code_elements_with_docstrings.json`** ‚Äì the file we just generated ‚Äì  \n",
    "and loads it into a Pandas DataFrame for a quick visual check.\n",
    "\n",
    "`elements` ‚Üí Python list of dicts  \n",
    "`df.head()` ‚Üí first few rows so we can confirm each entry now has a `docstring`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2c53aa91-240f-4498-838b-f6a9ccf42426",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>docstring</th>\n",
       "      <th>start_line</th>\n",
       "      <th>end_line</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>function_definition</td>\n",
       "      <td>root</td>\n",
       "      <td>Root endpoint to verify the API is running.</td>\n",
       "      <td>47</td>\n",
       "      <td>51</td>\n",
       "      <td>app/main.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>function_definition</td>\n",
       "      <td>health_check</td>\n",
       "      <td>Health check endpoint to verify the API is run...</td>\n",
       "      <td>54</td>\n",
       "      <td>58</td>\n",
       "      <td>app/main.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>function_definition</td>\n",
       "      <td>load_config</td>\n",
       "      <td>Load configuration from environment variables....</td>\n",
       "      <td>13</td>\n",
       "      <td>45</td>\n",
       "      <td>app/core/config.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>class_definition</td>\n",
       "      <td>Database</td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>1438</td>\n",
       "      <td>app/core/database.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>function_definition</td>\n",
       "      <td>__init__</td>\n",
       "      <td>Initialize the database connection with the gi...</td>\n",
       "      <td>15</td>\n",
       "      <td>32</td>\n",
       "      <td>app/core/database.py</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  type          name  \\\n",
       "0  function_definition          root   \n",
       "1  function_definition  health_check   \n",
       "2  function_definition   load_config   \n",
       "3     class_definition      Database   \n",
       "4  function_definition      __init__   \n",
       "\n",
       "                                           docstring  start_line  end_line  \\\n",
       "0        Root endpoint to verify the API is running.          47        51   \n",
       "1  Health check endpoint to verify the API is run...          54        58   \n",
       "2  Load configuration from environment variables....          13        45   \n",
       "3                                                             14      1438   \n",
       "4  Initialize the database connection with the gi...          15        32   \n",
       "\n",
       "                   file  \n",
       "0           app/main.py  \n",
       "1           app/main.py  \n",
       "2    app/core/config.py  \n",
       "3  app/core/database.py  \n",
       "4  app/core/database.py  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json, pandas as pd, networkx as nx\n",
    "from pathlib import Path\n",
    "\n",
    "with open(\"code_elements_with_docstrings.json\") as f:\n",
    "    elements = json.load(f)\n",
    "\n",
    "df = pd.DataFrame(elements)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268632cf-9ac0-4613-9261-48c488f5754e",
   "metadata": {},
   "source": [
    "## üßæ Requirement Graph ‚Äì build *similar_to* edges\n",
    "\n",
    "In this step we turn the list of elements into a **Requirement Graph (RG)**\n",
    "where each node is a docstring and edges connect semantically-similar nodes.\n",
    "\n",
    "What happens inside the code block:\n",
    "\n",
    "1. **Install** the embedding + math libs  \n",
    "   `sentence_transformers` ‚Üí text-to-vector model  \n",
    "   `scikit-learn` ‚Üí `cosine_similarity` helper\n",
    "2. **Embed** every docstring using the compact model  \n",
    "   (`all-MiniLM-L6-v2`, 384-dim).\n",
    "3. **Create** a NetworkX graph  \n",
    "   *Node ID*: `R0`, `R1`, ‚Ä¶ ‚Äì stores the original metadata.\n",
    "4. **Compute pairwise cosine similarity**  \n",
    "   If two requirements score **‚â• 0.80** we add  \n",
    "   `RG.add_edge(Ri, Rj, kind=\"similar_to\", weight=score)`.\n",
    "5. Finally we print a summary (`nx.info`) to check how many nodes and\n",
    "   *similar_to* edges were created.\n",
    "\n",
    "> **Threshold 0.80** is empirical ‚Äì adjust higher for stricter similarity,\n",
    "> lower for looser matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e674902b-4fea-40b8-9ba3-d96f272014e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -q sentence_transformers scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4caa1e7e-9f40-4807-b90e-6491362098e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "texts = [e[\"docstring\"] or \"\" for e in elements]\n",
    "emb = model.encode(texts, normalize_embeddings=True)\n",
    "\n",
    "RG = nx.Graph()\n",
    "\n",
    "# add nodes\n",
    "for idx, e in enumerate(elements):\n",
    "    RG.add_node(f\"R{idx}\", **e)\n",
    "\n",
    "# similarity edges\n",
    "cos_matrix = cosine_similarity(emb)\n",
    "THRESH = 0.8\n",
    "for i in range(len(elements)):\n",
    "    for j in range(i + 1, len(elements)):\n",
    "        if cos_matrix[i, j] >= THRESH:\n",
    "            RG.add_edge(f\"R{i}\", f\"R{j}\", kind=\"similar_to\", weight=float(cos_matrix[i, j]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b684876b-9c71-435a-991e-34ad75792063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RG: 102 nodes  |  127 similar_to edges\n"
     ]
    }
   ],
   "source": [
    "print(f\"RG: {RG.number_of_nodes():,} nodes  |  {RG.number_of_edges():,} similar_to edges\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aeae032b-22d9-4577-a454-758d5f48da25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes: 102\n",
      "Edges: 127\n",
      "Node examples: [('R0', {'type': 'function_definition', 'name': 'root', 'docstring': 'Root endpoint to verify the API is running.', 'start_line': 47, 'end_line': 51, 'file': 'app/main.py'}), ('R1', {'type': 'function_definition', 'name': 'health_check', 'docstring': 'Health check endpoint to verify the API is running.', 'start_line': 54, 'end_line': 58, 'file': 'app/main.py'}), ('R2', {'type': 'function_definition', 'name': 'load_config', 'docstring': 'Load configuration from environment variables.\\n\\nReturns:\\n    A dictionary containing configuration settings', 'start_line': 13, 'end_line': 45, 'file': 'app/core/config.py'})]\n"
     ]
    }
   ],
   "source": [
    "from networkx.classes.reportviews import NodeView, EdgeView\n",
    "print(\"Nodes:\", RG.number_of_nodes())\n",
    "print(\"Edges:\", RG.number_of_edges())\n",
    "print(\"Node examples:\", list(RG.nodes(data=True))[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e58aeb-2629-4e4d-b87f-492a07edb854",
   "metadata": {},
   "source": [
    "### 2.2 Add *parent_child* edges (calls)\n",
    "\n",
    "We already linked semantically similar requirements.  \n",
    "Now we‚Äôll connect a parent node to each requirement it **calls**:\n",
    "\n",
    "* Parse every `.py` file with `ast` to extract func ‚Üí func calls.  \n",
    "* When function **A** calls **B**, add `RG.add_edge(RA, RB, kind=\"parent_child\")`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "10ee355e-6932-452c-ad9b-6645d996bd76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent_child edges added. Graph now has 184 edges.\n"
     ]
    }
   ],
   "source": [
    "import ast, collections, itertools\n",
    "\n",
    "# 1. lookup (file, name)  ->  requirement ID\n",
    "name_to_rid = {\n",
    "    (data[\"file\"], data[\"name\"]): rid\n",
    "    for rid, data in RG.nodes(data=True)\n",
    "}\n",
    "\n",
    "def deepest_attr(node: ast.Attribute) -> str:\n",
    "    \"\"\"Return the last attribute name of a dotted call: pkg.mod.func -> func\"\"\"\n",
    "    while isinstance(node, ast.Attribute):\n",
    "        last = node.attr\n",
    "        node  = node.value\n",
    "    return last  # 'func'\n",
    "\n",
    "for py in ROOT.rglob(\"*.py\"):\n",
    "    src   = py.read_text(encoding=\"utf-8\")\n",
    "    mod   = ast.parse(src, filename=str(py))\n",
    "    file_ = str(py.relative_to(ROOT))\n",
    "\n",
    "    # todos los defs de este archivo\n",
    "    defs = {n.name: n for n in ast.walk(mod)\n",
    "            if isinstance(n, (ast.FunctionDef, ast.AsyncFunctionDef))}\n",
    "\n",
    "    for def_name, fn in defs.items():\n",
    "        rid_caller = name_to_rid.get((file_, def_name))\n",
    "        if not rid_caller:\n",
    "            continue\n",
    "\n",
    "        for call in ast.walk(fn):\n",
    "            if not isinstance(call, ast.Call):\n",
    "                continue\n",
    "\n",
    "            callee_name = None\n",
    "            # foo()\n",
    "            if isinstance(call.func, ast.Name):\n",
    "                callee_name = call.func.id\n",
    "            # obj.foo()  /  pkg.mod.bar()\n",
    "            elif isinstance(call.func, ast.Attribute):\n",
    "                callee_name = deepest_attr(call.func)\n",
    "\n",
    "            if callee_name:\n",
    "                rid_callee = name_to_rid.get((file_, callee_name))\n",
    "                if rid_callee:\n",
    "                    RG.add_edge(rid_caller, rid_callee, kind=\"parent_child\")\n",
    "\n",
    "print(f\"Parent_child edges added. Graph now has {RG.number_of_edges()} edges.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c78199cd-f0fd-4507-96df-3dfa19e95bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R4  app/core/database.py:__init__\n",
      "R5  app/core/database.py:_get_connection\n",
      "R5  app/core/database.py:_get_connection\n",
      "R5  app/core/database.py:_get_connection\n",
      "R5  app/core/database.py:_get_connection\n",
      "R5  app/core/database.py:_get_connection\n",
      "R5  app/core/database.py:_get_connection\n",
      "R5  app/core/database.py:_get_connection\n",
      "R5  app/core/database.py:_get_connection\n",
      "R5  app/core/database.py:_get_connection\n"
     ]
    }
   ],
   "source": [
    "parents = [\n",
    "    u for u, v, kind in RG.edges(data=\"kind\")\n",
    "    if kind == \"parent_child\"\n",
    "][:10]\n",
    "\n",
    "for rid in parents:\n",
    "    data = RG.nodes[rid]\n",
    "    print(f\"{rid}  {data['file']}:{data['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9d3caa55-6b17-4b2c-a09c-64d841befab7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_connection  ‚ûú calls  ‚ûú _create_tables\n",
      "get_connection  ‚ûú calls  ‚ûú save_thought\n",
      "get_connection  ‚ûú calls  ‚ûú get_thought\n",
      "get_connection  ‚ûú calls  ‚ûú get_thoughts\n",
      "get_connection  ‚ûú calls  ‚ûú create_procedure\n",
      "get_connection  ‚ûú calls  ‚ûú get_procedures\n",
      "get_connection  ‚ûú calls  ‚ûú get_procedure\n",
      "get_connection  ‚ûú calls  ‚ûú add_procedure_step\n",
      "get_connection  ‚ûú calls  ‚ûú add_procedure_steps\n",
      "get_connection  ‚ûú calls  ‚ûú delete_thought\n",
      "get_connection  ‚ûú calls  ‚ûú delete_procedure\n",
      "get_connection  ‚ûú calls  ‚ûú update_thought\n",
      "get_connection  ‚ûú calls  ‚ûú update_procedure\n",
      "get_connection  ‚ûú calls  ‚ûú update_procedure_step\n",
      "get_connection  ‚ûú calls  ‚ûú create_technical_decision\n",
      "get_connection  ‚ûú calls  ‚ûú get_technical_decisions\n",
      "get_connection  ‚ûú calls  ‚ûú get_technical_decision\n",
      "get_connection  ‚ûú calls  ‚ûú update_technical_decision\n",
      "get_connection  ‚ûú calls  ‚ûú delete_technical_decision\n",
      "get_connection  ‚ûú calls  ‚ûú create_experience\n",
      "get_connection  ‚ûú calls  ‚ûú get_experiences\n",
      "get_connection  ‚ûú calls  ‚ûú get_experience\n",
      "get_connection  ‚ûú calls  ‚ûú update_experience\n",
      "get_connection  ‚ûú calls  ‚ûú delete_experience\n"
     ]
    }
   ],
   "source": [
    "for u, v, k in RG.edges(data=\"kind\"):\n",
    "    if u == 'R5' and k == 'parent_child':   # R5 es un ejemplo; usa el RID que quieras\n",
    "        print(\"get_connection  ‚ûú calls  ‚ûú\", RG.nodes[v]['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24452ece-a2d8-40f6-bafa-41070f850074",
   "metadata": {},
   "source": [
    "### üëÄ Quick graph visualisation\n",
    "\n",
    "Below we draw **a small sub-graph** (up to 50 nodes) with NetworkX +\n",
    "Matplotlib.  \n",
    "For a full interactive view we also provide a PyVis snippet that writes an\n",
    "`html` file you can open in your browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dea47517-3d3f-4c38-bff2-3ba0d4eb02f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!pip install -q pyvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6692e3f0-0a61-4c06-a3c7-563d99d02c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: When  cdn_resources is 'local' jupyter notebook has issues displaying graphics on chrome/safari. Use cdn_resources='in_line' or cdn_resources='remote' if you have issues viewing graphics in a notebook.\n",
      "requirement_graph.html\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"750px\"\n",
       "            src=\"requirement_graph.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x32fcdf2f0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyvis.network import Network\n",
    "\n",
    "net = Network(height=\"750px\", width=\"100%\", notebook=True, directed=False)\n",
    "net.toggle_physics(True)\n",
    "\n",
    "for n, data in RG.nodes(data=True):\n",
    "    net.add_node(n, label=data[\"name\"], title=data[\"docstring\"][:200])\n",
    "\n",
    "for u, v, k in RG.edges(data=\"kind\"):\n",
    "    color = \"#2ca02c\" if k == \"parent_child\" else \"#9467bd\"\n",
    "    net.add_edge(u, v, color=color)\n",
    "\n",
    "net.show(\"requirement_graph.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4bf533-95c9-4580-b915-20c739a29e40",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ DS-Code Graph (CG) ‚Äì structure of the real code\n",
    "\n",
    "* **Nodes**\n",
    "  * **File / module**        ‚Üí id = file path\n",
    "  * **Function / Class**     ‚Üí id = `C0`, `C1`, ‚Ä¶\n",
    "\n",
    "* **Edges**\n",
    "  | Kind          | Added when ‚Ä¶                                          |\n",
    "  |---------------|-------------------------------------------------------|\n",
    "  | `contain`     | file ‚Üí func / class lives inside that file            |\n",
    "  | `call`        | function A calls function B (same file for now)       |\n",
    "  | `inherit`     | class A inherits from class B                         |\n",
    "  | `import`      | file A imports module/file B                          |\n",
    "  | `similar_to`  | _(optional)_ cosine ‚â• 0.80 between **code bodies**    |\n",
    "\n",
    "The graph is a `networkx.DiGraph` so edge direction matters  \n",
    "(`caller ‚Üí callee`, `file ‚Üí function`, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a965e3b3-0236-46d7-977d-5125707ca4b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CG built: 149 nodes  |  257 edges\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('C3', 'C6', 'call'),\n",
       " ('C3', 'C5', 'call'),\n",
       " ('C3', 'C8', 'call'),\n",
       " ('C3', 'C12', 'call'),\n",
       " ('C3', 'C22', 'call'),\n",
       " ('C3', 'C27', 'call'),\n",
       " ('C4', 'C6', 'call'),\n",
       " ('C6', 'C5', 'call'),\n",
       " ('C7', 'C5', 'call'),\n",
       " ('C8', 'C5', 'call')]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast, networkx as nx\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import json\n",
    "\n",
    "ROOT = Path(\".\").resolve()\n",
    "\n",
    "# ---------- load elements ----------\n",
    "with open(\"code_elements_with_docstrings.json\") as f:\n",
    "    elements = json.load(f)\n",
    "\n",
    "# helper: (file, name) -> code-node id\n",
    "cid_map = {}\n",
    "CG = nx.DiGraph()\n",
    "\n",
    "# ---------- add code nodes ----------\n",
    "for idx, el in enumerate(elements):\n",
    "    cid = f\"C{idx}\"\n",
    "    cid_map[(el[\"file\"], el[\"name\"])] = cid\n",
    "    CG.add_node(cid, **el)\n",
    "\n",
    "# ---------- add file nodes ----------\n",
    "for el in elements:\n",
    "    CG.add_node(el[\"file\"], type=\"module\")\n",
    "\n",
    "# ---------- contain edges ----------\n",
    "for idx, el in enumerate(elements):\n",
    "    CG.add_edge(el[\"file\"], f\"C{idx}\", kind=\"contain\")\n",
    "\n",
    "# ---------- scan every file with ast ----------\n",
    "for py in ROOT.rglob(\"*.py\"):\n",
    "    file_id = str(py.relative_to(ROOT))\n",
    "    src     = py.read_text(encoding=\"utf-8\")\n",
    "    tree    = ast.parse(src, filename=file_id)\n",
    "\n",
    "    # --- import edges (file -> imported module/file) ---\n",
    "    for node in ast.walk(tree):\n",
    "        if isinstance(node, ast.Import):\n",
    "            for n in node.names:\n",
    "                CG.add_edge(file_id, n.name, kind=\"import\")  # crude, module string\n",
    "        elif isinstance(node, ast.ImportFrom):\n",
    "            mod = node.module or \"\"\n",
    "            CG.add_edge(file_id, mod, kind=\"import\")\n",
    "\n",
    "    # --- call + inherit edges inside this file ---\n",
    "    defs = {n.name: n for n in ast.walk(tree)\n",
    "            if isinstance(n, (ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef))}\n",
    "\n",
    "    for def_name, obj in defs.items():\n",
    "        caller_cid = cid_map.get((file_id, def_name))\n",
    "        if not caller_cid:\n",
    "            continue\n",
    "\n",
    "        # inherit (classes only)\n",
    "        if isinstance(obj, ast.ClassDef):\n",
    "            for base in obj.bases:\n",
    "                if isinstance(base, ast.Name):\n",
    "                    parent_cid = cid_map.get((file_id, base.id))\n",
    "                    if parent_cid:\n",
    "                        CG.add_edge(caller_cid, parent_cid, kind=\"inherit\")\n",
    "\n",
    "        # call edges\n",
    "        for call in ast.walk(obj):\n",
    "            if isinstance(call, ast.Call):\n",
    "                # simple cases: foo(), obj.foo()\n",
    "                target_name = None\n",
    "                if isinstance(call.func, ast.Name):\n",
    "                    target_name = call.func.id\n",
    "                elif isinstance(call.func, ast.Attribute):\n",
    "                    target_name = call.func.attr\n",
    "                if target_name:\n",
    "                    callee_cid = cid_map.get((file_id, target_name))\n",
    "                    if callee_cid:\n",
    "                        CG.add_edge(caller_cid, callee_cid, kind=\"call\")\n",
    "\n",
    "print(f\"CG built: {CG.number_of_nodes()} nodes  |  {CG.number_of_edges()} edges\")\n",
    "\n",
    "# preview a few edges\n",
    "list(CG.edges(data=\"kind\"))[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6ee574-a347-4fbc-aa10-0080913a3015",
   "metadata": {},
   "source": [
    "### üîé 3.1 Quick sanity-checks for the Code Graph\n",
    "We‚Äôll print basic stats and inspect a few edges per kind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "30a939b8-0f46-41cc-ba44-8049a0676f3f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes: 149\n",
      "Edges: 257\n",
      "Edge types: Counter({'contain': 102, 'import': 79, 'call': 67, 'inherit': 9})\n",
      "Database  --call-->  _create_tables\n",
      "Database  --call-->  _get_connection\n",
      "Database  --call-->  get_thought\n",
      "Database  --call-->  get_procedure\n",
      "Database  --call-->  get_technical_decision\n",
      "Database  --call-->  get_experience\n",
      "__init__  --call-->  _create_tables\n",
      "_create_tables  --call-->  _get_connection\n",
      "save_thought  --call-->  _get_connection\n",
      "get_thought  --call-->  _get_connection\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "print(\"Nodes:\", CG.number_of_nodes())\n",
    "print(\"Edges:\", CG.number_of_edges())\n",
    "\n",
    "# distribuci√≥n por tipo de arista\n",
    "edge_kinds = Counter(k for _,_,k in CG.edges(data=\"kind\"))\n",
    "print(\"Edge types:\", edge_kinds)\n",
    "\n",
    "# ejemplo: ¬øqui√©n llama a qui√©n?\n",
    "for u, v, k in list(CG.edges(data=\"kind\"))[:10]:\n",
    "    print(f\"{CG.nodes[u]['name']}  --{k}-->  {CG.nodes[v]['name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ed70fc-fb4d-4aba-9691-a484acf9dfa8",
   "metadata": {},
   "source": [
    "### 4Ô∏è‚É£  ID map  (Requirement  ‚Üî  Code)  ‚Äì  the Bigraph glue\n",
    "We now link each requirement node `R*` to its corresponding code node `C*`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "64bf02ff-d5b7-4ee4-949c-86fd4c221ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigraph mapping added: 102 links\n"
     ]
    }
   ],
   "source": [
    "# 1-to-1 map (por construcci√≥n los √≠ndices coinciden)\n",
    "id_map = {f\"R{i}\": f\"C{i}\" for i in range(len(elements))}\n",
    "\n",
    "# guardamos como atributo cruzado\n",
    "for rid, cid in id_map.items():\n",
    "    RG.nodes[rid][\"code_id\"] = cid\n",
    "    CG.nodes[cid][\"req_id\"]  = rid\n",
    "print(\"Bigraph mapping added:\", len(id_map), \"links\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a2dbda-10e4-469e-9e4a-7ac27eab0bb0",
   "metadata": {},
   "source": [
    "### üíæ Persist graphs to disk\n",
    "\n",
    "We‚Äôll save both graphs in **GraphML** format so they can be:\n",
    "\n",
    "* Reloaded later in NetworkX without rebuilding.\n",
    "* Imported into Neo4j (via `neo4j-admin import`) or visual tools like Gephi.\n",
    "\n",
    "Files created:\n",
    "\n",
    "* `requirement_graph.graphml`\n",
    "* `code_graph.graphml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "caa2c83d-e151-4e55-8140-163ba13e13ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_graphml(RG, \"requirement_graph.graphml\")\n",
    "nx.write_graphml(CG, \"code_graph.graphml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab9073d-0e71-4755-afa5-8bee060c21af",
   "metadata": {},
   "source": [
    "### üîç Mini-demo ‚Äî ‚ÄúWhat does X call and who is similar?‚Äù\n",
    "\n",
    "Give a function/class name, and we‚Äôll:\n",
    "\n",
    "1. Locate its requirement node in **RG**  \n",
    "2. Display its docstring  \n",
    "3. Show *similar* requirements (semantic)  \n",
    "4. Show *children it calls* (parent_child edges)  \n",
    "5. Print the source code for context\n",
    "\n",
    "This proves the graphs are usable right away."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "433925a8-e968-4c25-bf9b-f9380b6be9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import textwrap\n",
    "\n",
    "def show_info(func_name: str, file_hint: str = None):\n",
    "    \"\"\"\n",
    "    Quick graph-based inspection tool.\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    func_name : name of the function/class to inspect\n",
    "    file_hint : optional relative file path if several defs share the same name\n",
    "    \"\"\"\n",
    "    # 1Ô∏è‚É£ find node id\n",
    "    candidates = [\n",
    "        rid for rid, data in RG.nodes(data=True)\n",
    "        if data[\"name\"] == func_name\n",
    "           and (file_hint is None or data[\"file\"] == file_hint)\n",
    "    ]\n",
    "    if not candidates:\n",
    "        print(\"‚ùå Not found\")\n",
    "        return\n",
    "    rid = candidates[0]\n",
    "    data = RG.nodes[rid]\n",
    "    print(f\"### {data['name']}  ({data['file']}:{data['start_line']}-{data['end_line']})\\n\")\n",
    "    print(textwrap.indent(data[\"docstring\"] or \"*(no docstring)*\", \"  \"))\n",
    "\n",
    "    # 2Ô∏è‚É£ similar requirements\n",
    "    similars = [\n",
    "        v for u, v, kind in RG.edges(rid, data=\"kind\")\n",
    "        if kind == \"similar_to\"\n",
    "    ][:5]\n",
    "    print(\"\\n‚Äî Similar requirements:\")\n",
    "    for v in similars:\n",
    "        print(\" ‚Ä¢\", RG.nodes[v][\"name\"])\n",
    "\n",
    "    # 3Ô∏è‚É£ child calls\n",
    "    childs = [\n",
    "        v for u, v, kind in RG.edges(rid, data=\"kind\")\n",
    "        if kind == \"parent_child\"\n",
    "    ][:10]\n",
    "    print(\"\\n‚Äî Direct calls (parent_child):\")\n",
    "    for v in childs:\n",
    "        print(\" ‚Ä¢\", RG.nodes[v][\"name\"])\n",
    "\n",
    "    # 4Ô∏è‚É£ show code\n",
    "    code_path = Path(data[\"file\"])\n",
    "    code_lines = code_path.read_text(encoding=\"utf-8\").splitlines()\n",
    "    snippet = code_lines[data[\"start_line\"]-1 : data[\"end_line\"]]\n",
    "    print(\"\\n‚Äî Source code:\")\n",
    "    print(textwrap.indent(\"\\n\".join(snippet), \"    \"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "415bf16d-c008-4d12-a8c1-e2316d13f9f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### update_technical_decision  (app/core/database.py:1014-1099)\n",
      "\n",
      "  Update a technical decision in the database.\n",
      "\n",
      "  Args:\n",
      "      decision_id: The ID of the technical decision to update\n",
      "      data: Dictionary containing the fields to update\n",
      "    \n",
      "  Returns:\n",
      "      The updated technical decision data, or None if not found or error\n",
      "\n",
      "‚Äî Similar requirements:\n",
      " ‚Ä¢ update_technical_decision\n",
      "\n",
      "‚Äî Direct calls (parent_child):\n",
      " ‚Ä¢ _get_connection\n",
      " ‚Ä¢ get_technical_decision\n",
      "\n",
      "‚Äî Source code:\n",
      "        def update_technical_decision(self, decision_id: int, data: Dict[str, Any]) -> Optional[Dict[str, Any]]:\n",
      "            \"\"\"\n",
      "            Update a technical decision in the database.\n",
      "        \n",
      "            Args:\n",
      "                decision_id: The ID of the technical decision to update\n",
      "                data: Dictionary containing the fields to update\n",
      "            \n",
      "            Returns:\n",
      "                The updated technical decision data, or None if not found or error\n",
      "            \"\"\"\n",
      "            try:\n",
      "                conn = self._get_connection()\n",
      "                cursor = conn.cursor()\n",
      "            \n",
      "                # Check if technical decision exists\n",
      "                cursor.execute(\n",
      "                    \"SELECT id FROM technical_decisions WHERE id = %s\",\n",
      "                    (decision_id,)\n",
      "                )\n",
      "            \n",
      "                if not cursor.fetchone():\n",
      "                    cursor.close()\n",
      "                    conn.close()\n",
      "                    logger.warning(f\"Technical decision with ID {decision_id} not found for update\")\n",
      "                    return None\n",
      "            \n",
      "                # Build the update query dynamically based on provided fields\n",
      "                update_fields = []\n",
      "                update_values = []\n",
      "            \n",
      "                field_mapping = {\n",
      "                    'title': 'title = %s',\n",
      "                    'context': 'context = %s',\n",
      "                    'decision': 'decision = %s',\n",
      "                    'reasoning': 'reasoning = %s',\n",
      "                    'alternatives': 'alternatives = %s',\n",
      "                    'consequences': 'consequences = %s',\n",
      "                    'tags': 'tags = %s',\n",
      "                    'related_resources': 'related_resources = %s'\n",
      "                }\n",
      "            \n",
      "                for field, sql_field in field_mapping.items():\n",
      "                    if field in data and data[field] is not None:\n",
      "                        update_fields.append(sql_field)\n",
      "                        # Handle JSONB field specially\n",
      "                        if field == 'alternatives':\n",
      "                            update_values.append(json.dumps(data[field]))\n",
      "                        else:\n",
      "                            update_values.append(data[field])\n",
      "            \n",
      "                # Always update the updated_at timestamp\n",
      "                update_fields.append(\"updated_at = %s\")\n",
      "                update_values.append(datetime.now())\n",
      "            \n",
      "                if not update_fields:\n",
      "                    cursor.close()\n",
      "                    conn.close()\n",
      "                    logger.warning(\"No fields to update for technical decision\")\n",
      "                    return self.get_technical_decision(decision_id)  # Return current state if no updates\n",
      "            \n",
      "                # Construct and execute the update query\n",
      "                update_query = f\"\"\"\n",
      "                    UPDATE technical_decisions\n",
      "                    SET {', '.join(update_fields)}\n",
      "                    WHERE id = %s\n",
      "                    RETURNING id\n",
      "                \"\"\"\n",
      "            \n",
      "                update_values.append(decision_id)  # Add the ID for the WHERE clause\n",
      "            \n",
      "                cursor.execute(update_query, update_values)\n",
      "                updated = cursor.fetchone()\n",
      "                conn.commit()\n",
      "                cursor.close()\n",
      "                conn.close()\n",
      "            \n",
      "                if updated:\n",
      "                    logger.info(f\"Technical decision with ID {decision_id} updated successfully\")\n",
      "                    return self.get_technical_decision(decision_id)  # Get the updated technical decision\n",
      "                else:\n",
      "                    logger.warning(f\"Failed to update technical decision with ID {decision_id}\")\n",
      "                    return None\n",
      "            except Exception as e:\n",
      "                logger.error(f\"Error updating technical decision: {str(e)}\")\n",
      "                return None\n"
     ]
    }
   ],
   "source": [
    "show_info(\"update_technical_decision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e84a4d-89ff-4917-ac3c-b0d708928abc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
