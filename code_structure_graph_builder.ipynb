{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d8a1721-02df-4e79-b9b7-083bc43afa30",
   "metadata": {},
   "source": [
    "# üß† GPT now understands my repo like a senior dev ‚Äì here's how\n",
    "\n",
    "This notebook is an end-to-end reproduction and reinterpretation of the **CodeRAG** framework (see [paper](https://arxiv.org/pdf/2504.10046)), adapted to run locally on your own codebase.\n",
    "\n",
    "We want to give GPT (or any LLM) the ability to:\n",
    "- Parse and **understand your entire repo**\n",
    "- Retrieve and reason over related code\n",
    "- Answer questions like a senior developer would ‚Äî with **zero fine-tuning**\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Goal of this experiment\n",
    "\n",
    "Our objective is to build a **code-aware assistant** using a combination of:\n",
    "\n",
    "- üîç **Tree-sitter** to parse and structure the codebase\n",
    "- üß† **LLMs** to describe each function or class (aka \"requirements\")\n",
    "- üï∏Ô∏è **Code graphs** to represent dependencies (calls, imports, etc)\n",
    "- üß≠ **Agentic reasoning** to let the LLM query and retrieve context dynamically\n",
    "- ‚ö° **RAG (Retrieval-Augmented Generation)** to reduce hallucinations and give smarter answers\n",
    "\n",
    "The end result is a local-first, fully transparent, and extensible RAG pipeline tailored for your own project.\n",
    "\n",
    "---\n",
    "\n",
    "## üß™ Inspired by CodeRAG (What we're replicating)\n",
    "\n",
    "From the CodeRAG paper (April 2025), we aim to recreate the following innovations:\n",
    "\n",
    "1. **Requirement Graph**  \n",
    "   A graph where each node is a *natural language description* of a function or class. Edges represent semantic similarity or parent-child relations.\n",
    "\n",
    "2. **DS-Code Graph**  \n",
    "   A code graph that encodes structural dependencies like:\n",
    "   - function calls\n",
    "   - class inheritance\n",
    "   - file/module containment\n",
    "   - semantic similarity (via embeddings)\n",
    "\n",
    "3. **BiGraph Mapping**  \n",
    "   Links between requirements and code elements ‚Äî allowing retrieval of relevant code given a high-level prompt.\n",
    "\n",
    "4. **Agentic Reasoning**  \n",
    "   An LLM-driven reasoning loop that dynamically:\n",
    "   - queries the graph\n",
    "   - follows dependencies\n",
    "   - does web search if needed\n",
    "   - formats and tests generated code\n",
    "\n",
    "---\n",
    "\n",
    "## ü™ú Pipeline Overview (what this notebook covers)\n",
    "\n",
    "| Step | Description |\n",
    "|------|-------------|\n",
    "| ‚úÖ 1. Parse your local repo using Tree-sitter |\n",
    "| ‚úÖ 2. Extract all functions and classes |\n",
    "| ‚úÖ 3. Generate descriptions for each (via LLM) |\n",
    "| ‚úÖ 4. Build the **Requirement Graph** |\n",
    "| ‚úÖ 5. Build the **DS-Code Graph** |\n",
    "| ‚úÖ 6. Link both graphs into a BiGraph |\n",
    "| ‚úÖ 7. Implement a simple **agentic loop** using ReAct |\n",
    "| ‚úÖ 8. Let GPT answer deep questions about your code (with full context) |\n",
    "\n",
    "---\n",
    "\n",
    "## üß∞ Tech Stack\n",
    "\n",
    "| Component        | Tool                            |\n",
    "|------------------|---------------------------------|\n",
    "| Parsing          | `tree-sitter-language-pack`     |\n",
    "| Description gen. | OpenAI / DeepSeek-V2.5          |\n",
    "| Graph storage    | Neo4j                           |\n",
    "| Semantic sim.    | HuggingFace Transformers        |\n",
    "| Reasoning agent  | Custom ReAct (or LangChain)     |\n",
    "| Validation       | `black`, `pytest`, `mypy`       |\n",
    "\n",
    "---\n",
    "\n",
    "## üîó References & Credits\n",
    "\n",
    "- [CodeRAG: Supportive Code Retrieval on Bigraph for Real-World Code Generation](https://arxiv.org/pdf/2504.10046)\n",
    "- [Self-RAG (Asai et al., 2023)](https://arxiv.org/pdf/2307.05068)\n",
    "- [DRAGIN: Dynamic RAG for real-time needs](https://arxiv.org/pdf/2501.13742)\n",
    "- [CodeRAG benchmark (June 2024)](https://arxiv.org/pdf/2406.14497)\n",
    "\n",
    "---\n",
    "\n",
    "üëâ Let‚Äôs get started by parsing the repo with Tree-sitter..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bbbf10-7219-41aa-ab35-ae06a06fb5f8",
   "metadata": {},
   "source": [
    "## üì¶ Install dependencies\n",
    "\n",
    "We‚Äôll begin by installing the `tree-sitter-language-pack` Python library, which provides precompiled Tree-sitter grammars for popular languages ‚Äî including Python.\n",
    "\n",
    "This saves us from having to manually clone grammars or compile `.so` libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5baed20f-b420-4afd-87a2-819ed4bf6c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tree-sitter-language-pack in /opt/anaconda3/lib/python3.12/site-packages (0.8.0)\n",
      "Requirement already satisfied: tree-sitter>=0.23.2 in /opt/anaconda3/lib/python3.12/site-packages (from tree-sitter-language-pack) (0.24.0)\n",
      "Requirement already satisfied: tree-sitter-c-sharp>=0.23.1 in /opt/anaconda3/lib/python3.12/site-packages (from tree-sitter-language-pack) (0.23.1)\n",
      "Requirement already satisfied: tree-sitter-embedded-template>=0.23.2 in /opt/anaconda3/lib/python3.12/site-packages (from tree-sitter-language-pack) (0.23.2)\n",
      "Requirement already satisfied: tree-sitter-yaml>=0.7.0 in /opt/anaconda3/lib/python3.12/site-packages (from tree-sitter-language-pack) (0.7.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tree-sitter-language-pack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55627cc9-16a1-4989-8851-c739c9586824",
   "metadata": {},
   "source": [
    "## üß™ Parse a test string with Tree-sitter\n",
    "\n",
    "Let's load the Python parser and run Tree-sitter on a simple test snippet to confirm everything is working.\n",
    "\n",
    "We also define a small `dump()` helper function to pretty-print the AST (abstract syntax tree) node structure.\n",
    "\n",
    "This will help us verify that Tree-sitter is correctly parsing the function and its components (name, parameters, body, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a213375-9fa7-48bc-be27-0683df2f6027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module: def foo(): pass\n",
      "  function_definition: def foo(): pass\n",
      "    identifier: foo\n",
      "    parameters: ()\n",
      "    block: pass\n",
      "      pass_statement: pass\n"
     ]
    }
   ],
   "source": [
    "from tree_sitter_language_pack import get_parser\n",
    "\n",
    "parser = get_parser(\"python\")\n",
    "tree = parser.parse(b\"def foo(): pass\")\n",
    "\n",
    "def dump(node, indent=0):\n",
    "    print(\"  \" * indent + f\"{node.type}: {node.text.decode('utf-8')}\")\n",
    "    for child in node.named_children:\n",
    "        dump(child, indent + 1)\n",
    "\n",
    "root = parser.parse(b\"def foo(): pass\").root_node\n",
    "dump(root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1934e129-9a69-4bd9-bbea-91e73a1261f7",
   "metadata": {},
   "source": [
    "## üìÇ Parse all Python files in the repo\n",
    "\n",
    "Now that Tree-sitter is working, let‚Äôs walk through the entire local repo and extract all `function_definition` and `class_definition` nodes.\n",
    "\n",
    "For each one, we‚Äôll collect:\n",
    "\n",
    "- Type (`function` or `class`)\n",
    "- Name\n",
    "- Start and end line\n",
    "- File path\n",
    "\n",
    "This structured data will help us build the code graph later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e543255f-8a51-48eb-9f8a-aa9cd536129d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tree_sitter_language_pack import get_parser\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# Setup\n",
    "parser = get_parser(\"python\")\n",
    "REPO_ROOT = Path(\".\").resolve()\n",
    "\n",
    "# Extract function/class nodes\n",
    "def extract_code_elements(source_code: str, file_path: str):\n",
    "    tree = parser.parse(bytes(source_code, \"utf-8\"))\n",
    "    root = tree.root_node\n",
    "    elements = []\n",
    "\n",
    "    def visit(node):\n",
    "        if node.type in (\"function_definition\", \"class_definition\"):\n",
    "            name_node = node.child_by_field_name(\"name\")\n",
    "            name = name_node.text.decode(\"utf-8\") if name_node else \"<anonymous>\"\n",
    "            elements.append({\n",
    "                \"type\": node.type,\n",
    "                \"name\": name,\n",
    "                \"start_line\": node.start_point[0] + 1,\n",
    "                \"end_line\": node.end_point[0] + 1,\n",
    "                \"file\": str(file_path)\n",
    "            })\n",
    "        for child in node.named_children:\n",
    "            visit(child)\n",
    "\n",
    "    visit(root)\n",
    "    return elements\n",
    "\n",
    "# Walk through repo\n",
    "all_elements = []\n",
    "for py_file in REPO_ROOT.rglob(\"*.py\"):\n",
    "    try:\n",
    "        code = py_file.read_text(encoding=\"utf-8\")\n",
    "        extracted = extract_code_elements(code, py_file.relative_to(REPO_ROOT))\n",
    "        all_elements.extend(extracted)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Failed to parse {py_file}: {e}\")\n",
    "\n",
    "# Save results\n",
    "with open(\"code_elements.json\", \"w\") as f:\n",
    "    json.dump(all_elements, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56dd4ee-d962-4858-8615-434882ef0bbb",
   "metadata": {},
   "source": [
    "## üßæ Requirement Descriptions (Docstrings)\n",
    "\n",
    "In this project, we assume that each function and class in the codebase already includes a properly written **docstring** that describes its purpose, inputs, and outputs.\n",
    "\n",
    "This serves as the \"requirement\" we need for building the **Requirement Graph** in the next step.\n",
    "\n",
    "> ‚ö†Ô∏è If the codebase lacks docstrings or uses inconsistent formatting, you would need to generate these descriptions using a language model (e.g. GPT-4 or DeepSeek) based on the raw source code.\n",
    "\n",
    "Since our current dataset is clean and well-documented, we‚Äôll skip this step and move directly to extracting docstrings from the parsed code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116bbb04-2696-45c5-bd83-177a37352973",
   "metadata": {},
   "source": [
    "### üîÑ Extract docstrings with Python `ast`\n",
    "\n",
    "Tree-sitter gives us positions, calls, etc.  \n",
    "For docstrings the built-in `ast` module is simpler and bullet-proof.\n",
    "This cell parses each file twice:\n",
    "\n",
    "* Tree-sitter ‚Üí start/end lines, names, calls (as before)  \n",
    "* AST ‚Üí exact docstring for every func/class  \n",
    "\n",
    "The result is `code_elements_with_docstrings.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8539ed5f-4257-4ef8-8fa5-fe03eb07acae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ saved 102 elements with docstrings\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>docstring</th>\n",
       "      <th>start_line</th>\n",
       "      <th>end_line</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>function_definition</td>\n",
       "      <td>root</td>\n",
       "      <td>Root endpoint to verify the API is running.</td>\n",
       "      <td>47</td>\n",
       "      <td>51</td>\n",
       "      <td>app/main.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>function_definition</td>\n",
       "      <td>health_check</td>\n",
       "      <td>Health check endpoint to verify the API is run...</td>\n",
       "      <td>54</td>\n",
       "      <td>58</td>\n",
       "      <td>app/main.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>function_definition</td>\n",
       "      <td>load_config</td>\n",
       "      <td>Load configuration from environment variables....</td>\n",
       "      <td>13</td>\n",
       "      <td>45</td>\n",
       "      <td>app/core/config.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>class_definition</td>\n",
       "      <td>Database</td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>1438</td>\n",
       "      <td>app/core/database.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>function_definition</td>\n",
       "      <td>__init__</td>\n",
       "      <td>Initialize the database connection with the gi...</td>\n",
       "      <td>15</td>\n",
       "      <td>32</td>\n",
       "      <td>app/core/database.py</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  type          name  \\\n",
       "0  function_definition          root   \n",
       "1  function_definition  health_check   \n",
       "2  function_definition   load_config   \n",
       "3     class_definition      Database   \n",
       "4  function_definition      __init__   \n",
       "\n",
       "                                           docstring  start_line  end_line  \\\n",
       "0        Root endpoint to verify the API is running.          47        51   \n",
       "1  Health check endpoint to verify the API is run...          54        58   \n",
       "2  Load configuration from environment variables....          13        45   \n",
       "3                                                             14      1438   \n",
       "4  Initialize the database connection with the gi...          15        32   \n",
       "\n",
       "                   file  \n",
       "0           app/main.py  \n",
       "1           app/main.py  \n",
       "2    app/core/config.py  \n",
       "3  app/core/database.py  \n",
       "4  app/core/database.py  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast, json, pandas as pd\n",
    "from tree_sitter_language_pack import get_parser\n",
    "from pathlib import Path\n",
    "\n",
    "parser = get_parser(\"python\")\n",
    "ROOT   = Path(\".\").resolve()\n",
    "out    = []\n",
    "\n",
    "def ts_name_and_span(src: str):\n",
    "    \"\"\"Return dict {name,start,end} for every function/class via Tree-sitter.\"\"\"\n",
    "    tree = parser.parse(src.encode())\n",
    "    root = tree.root_node\n",
    "    res  = []\n",
    "\n",
    "    def walk(node):\n",
    "        if node.type in (\"function_definition\", \"class_definition\"):\n",
    "            name = node.child_by_field_name(\"name\").text.decode()\n",
    "            res.append((name, node.start_point[0]+1, node.end_point[0]+1))\n",
    "        for c in node.named_children:\n",
    "            walk(c)\n",
    "    walk(root)\n",
    "    return res\n",
    "\n",
    "for py in ROOT.rglob(\"*.py\"):\n",
    "    code = py.read_text(encoding=\"utf-8\")\n",
    "    # 1Ô∏è‚É£ positions with tree-sitter\n",
    "    spans = ts_name_and_span(code)\n",
    "    # 2Ô∏è‚É£ docstrings with ast\n",
    "    module = ast.parse(code, filename=str(py))\n",
    "    for node in ast.walk(module):\n",
    "        if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef)):\n",
    "            doc = ast.get_docstring(node) or \"\"\n",
    "            name = node.name\n",
    "            # match span (name is unique inside file)\n",
    "            start, end = next((s,e) for n,s,e in spans if n == name)\n",
    "            out.append({\n",
    "                \"type\": \"class_definition\" if isinstance(node, ast.ClassDef) else \"function_definition\",\n",
    "                \"name\": name,\n",
    "                \"docstring\": doc,\n",
    "                \"start_line\": start,\n",
    "                \"end_line\": end,\n",
    "                \"file\": str(py.relative_to(ROOT))\n",
    "            })\n",
    "\n",
    "with open(\"code_elements_with_docstrings.json\", \"w\") as f:\n",
    "    json.dump(out, f, indent=2)\n",
    "print(\"‚úÖ saved\", len(out), \"elements with docstrings\")\n",
    "pd.DataFrame(out).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828125fc-230b-441e-9f10-29b7d1a57f08",
   "metadata": {},
   "source": [
    "## üì• Load elements (docstrings included)\n",
    "\n",
    "This cell reads **`code_elements_with_docstrings.json`** ‚Äì the file we just generated ‚Äì  \n",
    "and loads it into a Pandas DataFrame for a quick visual check.\n",
    "\n",
    "`elements` ‚Üí Python list of dicts  \n",
    "`df.head()` ‚Üí first few rows so we can confirm each entry now has a `docstring`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c53aa91-240f-4498-838b-f6a9ccf42426",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>docstring</th>\n",
       "      <th>start_line</th>\n",
       "      <th>end_line</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>function_definition</td>\n",
       "      <td>root</td>\n",
       "      <td>Root endpoint to verify the API is running.</td>\n",
       "      <td>47</td>\n",
       "      <td>51</td>\n",
       "      <td>app/main.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>function_definition</td>\n",
       "      <td>health_check</td>\n",
       "      <td>Health check endpoint to verify the API is run...</td>\n",
       "      <td>54</td>\n",
       "      <td>58</td>\n",
       "      <td>app/main.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>function_definition</td>\n",
       "      <td>load_config</td>\n",
       "      <td>Load configuration from environment variables....</td>\n",
       "      <td>13</td>\n",
       "      <td>45</td>\n",
       "      <td>app/core/config.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>class_definition</td>\n",
       "      <td>Database</td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>1438</td>\n",
       "      <td>app/core/database.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>function_definition</td>\n",
       "      <td>__init__</td>\n",
       "      <td>Initialize the database connection with the gi...</td>\n",
       "      <td>15</td>\n",
       "      <td>32</td>\n",
       "      <td>app/core/database.py</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  type          name  \\\n",
       "0  function_definition          root   \n",
       "1  function_definition  health_check   \n",
       "2  function_definition   load_config   \n",
       "3     class_definition      Database   \n",
       "4  function_definition      __init__   \n",
       "\n",
       "                                           docstring  start_line  end_line  \\\n",
       "0        Root endpoint to verify the API is running.          47        51   \n",
       "1  Health check endpoint to verify the API is run...          54        58   \n",
       "2  Load configuration from environment variables....          13        45   \n",
       "3                                                             14      1438   \n",
       "4  Initialize the database connection with the gi...          15        32   \n",
       "\n",
       "                   file  \n",
       "0           app/main.py  \n",
       "1           app/main.py  \n",
       "2    app/core/config.py  \n",
       "3  app/core/database.py  \n",
       "4  app/core/database.py  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json, pandas as pd, networkx as nx\n",
    "from pathlib import Path\n",
    "\n",
    "with open(\"code_elements_with_docstrings.json\") as f:\n",
    "    elements = json.load(f)\n",
    "\n",
    "df = pd.DataFrame(elements)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268632cf-9ac0-4613-9261-48c488f5754e",
   "metadata": {},
   "source": [
    "## üßæ Requirement Graph ‚Äì build *similar_to* edges\n",
    "\n",
    "In this step we turn the list of elements into a **Requirement Graph (RG)**\n",
    "where each node is a docstring and edges connect semantically-similar nodes.\n",
    "\n",
    "What happens inside the code block:\n",
    "\n",
    "1. **Install** the embedding + math libs  \n",
    "   `sentence_transformers` ‚Üí text-to-vector model  \n",
    "   `scikit-learn` ‚Üí `cosine_similarity` helper\n",
    "2. **Embed** every docstring using the compact model  \n",
    "   (`all-MiniLM-L6-v2`, 384-dim).\n",
    "3. **Create** a NetworkX graph  \n",
    "   *Node ID*: `R0`, `R1`, ‚Ä¶ ‚Äì stores the original metadata.\n",
    "4. **Compute pairwise cosine similarity**  \n",
    "   If two requirements score **‚â• 0.80** we add  \n",
    "   `RG.add_edge(Ri, Rj, kind=\"similar_to\", weight=score)`.\n",
    "5. Finally we print a summary (`nx.info`) to check how many nodes and\n",
    "   *similar_to* edges were created.\n",
    "\n",
    "> **Threshold 0.80** is empirical ‚Äì adjust higher for stricter similarity,\n",
    "> lower for looser matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e674902b-4fea-40b8-9ba3-d96f272014e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -q sentence_transformers scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4caa1e7e-9f40-4807-b90e-6491362098e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "texts = [e[\"docstring\"] or \"\" for e in elements]\n",
    "emb = model.encode(texts, normalize_embeddings=True)\n",
    "\n",
    "RG = nx.Graph()\n",
    "\n",
    "# add nodes\n",
    "for idx, e in enumerate(elements):\n",
    "    RG.add_node(f\"R{idx}\", **e)\n",
    "\n",
    "# similarity edges\n",
    "cos_matrix = cosine_similarity(emb)\n",
    "THRESH = 0.8\n",
    "for i in range(len(elements)):\n",
    "    for j in range(i + 1, len(elements)):\n",
    "        if cos_matrix[i, j] >= THRESH:\n",
    "            RG.add_edge(f\"R{i}\", f\"R{j}\", kind=\"similar_to\", weight=float(cos_matrix[i, j]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b684876b-9c71-435a-991e-34ad75792063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RG: 102 nodes  |  127 similar_to edges\n"
     ]
    }
   ],
   "source": [
    "print(f\"RG: {RG.number_of_nodes():,} nodes  |  {RG.number_of_edges():,} similar_to edges\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aeae032b-22d9-4577-a454-758d5f48da25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes: 102\n",
      "Edges: 127\n",
      "Node examples: [('R0', {'type': 'function_definition', 'name': 'root', 'docstring': 'Root endpoint to verify the API is running.', 'start_line': 47, 'end_line': 51, 'file': 'app/main.py'}), ('R1', {'type': 'function_definition', 'name': 'health_check', 'docstring': 'Health check endpoint to verify the API is running.', 'start_line': 54, 'end_line': 58, 'file': 'app/main.py'}), ('R2', {'type': 'function_definition', 'name': 'load_config', 'docstring': 'Load configuration from environment variables.\\n\\nReturns:\\n    A dictionary containing configuration settings', 'start_line': 13, 'end_line': 45, 'file': 'app/core/config.py'})]\n"
     ]
    }
   ],
   "source": [
    "from networkx.classes.reportviews import NodeView, EdgeView\n",
    "print(\"Nodes:\", RG.number_of_nodes())\n",
    "print(\"Edges:\", RG.number_of_edges())\n",
    "print(\"Node examples:\", list(RG.nodes(data=True))[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e58aeb-2629-4e4d-b87f-492a07edb854",
   "metadata": {},
   "source": [
    "### 2.2 Add *parent_child* edges (calls)\n",
    "\n",
    "We already linked semantically similar requirements.  \n",
    "Now we‚Äôll connect a parent node to each requirement it **calls**:\n",
    "\n",
    "* Parse every `.py` file with `ast` to extract func ‚Üí func calls.  \n",
    "* When function **A** calls **B**, add `RG.add_edge(RA, RB, kind=\"parent_child\")`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10ee355e-6932-452c-ad9b-6645d996bd76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent_child edges added. Graph now has 184 edges.\n"
     ]
    }
   ],
   "source": [
    "import ast, collections, itertools\n",
    "\n",
    "# 1. lookup (file, name)  ->  requirement ID\n",
    "name_to_rid = {\n",
    "    (data[\"file\"], data[\"name\"]): rid\n",
    "    for rid, data in RG.nodes(data=True)\n",
    "}\n",
    "\n",
    "def deepest_attr(node: ast.Attribute) -> str:\n",
    "    \"\"\"Return the last attribute name of a dotted call: pkg.mod.func -> func\"\"\"\n",
    "    while isinstance(node, ast.Attribute):\n",
    "        last = node.attr\n",
    "        node  = node.value\n",
    "    return last  # 'func'\n",
    "\n",
    "for py in ROOT.rglob(\"*.py\"):\n",
    "    src   = py.read_text(encoding=\"utf-8\")\n",
    "    mod   = ast.parse(src, filename=str(py))\n",
    "    file_ = str(py.relative_to(ROOT))\n",
    "\n",
    "    # todos los defs de este archivo\n",
    "    defs = {n.name: n for n in ast.walk(mod)\n",
    "            if isinstance(n, (ast.FunctionDef, ast.AsyncFunctionDef))}\n",
    "\n",
    "    for def_name, fn in defs.items():\n",
    "        rid_caller = name_to_rid.get((file_, def_name))\n",
    "        if not rid_caller:\n",
    "            continue\n",
    "\n",
    "        for call in ast.walk(fn):\n",
    "            if not isinstance(call, ast.Call):\n",
    "                continue\n",
    "\n",
    "            callee_name = None\n",
    "            # foo()\n",
    "            if isinstance(call.func, ast.Name):\n",
    "                callee_name = call.func.id\n",
    "            # obj.foo()  /  pkg.mod.bar()\n",
    "            elif isinstance(call.func, ast.Attribute):\n",
    "                callee_name = deepest_attr(call.func)\n",
    "\n",
    "            if callee_name:\n",
    "                rid_callee = name_to_rid.get((file_, callee_name))\n",
    "                if rid_callee:\n",
    "                    RG.add_edge(rid_caller, rid_callee, kind=\"parent_child\")\n",
    "\n",
    "print(f\"Parent_child edges added. Graph now has {RG.number_of_edges()} edges.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c78199cd-f0fd-4507-96df-3dfa19e95bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R4  app/core/database.py:__init__\n",
      "R5  app/core/database.py:_get_connection\n",
      "R5  app/core/database.py:_get_connection\n",
      "R5  app/core/database.py:_get_connection\n",
      "R5  app/core/database.py:_get_connection\n",
      "R5  app/core/database.py:_get_connection\n",
      "R5  app/core/database.py:_get_connection\n",
      "R5  app/core/database.py:_get_connection\n",
      "R5  app/core/database.py:_get_connection\n",
      "R5  app/core/database.py:_get_connection\n"
     ]
    }
   ],
   "source": [
    "parents = [\n",
    "    u for u, v, kind in RG.edges(data=\"kind\")\n",
    "    if kind == \"parent_child\"\n",
    "][:10]\n",
    "\n",
    "for rid in parents:\n",
    "    data = RG.nodes[rid]\n",
    "    print(f\"{rid}  {data['file']}:{data['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d3caa55-6b17-4b2c-a09c-64d841befab7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_connection  ‚ûú calls  ‚ûú _create_tables\n",
      "get_connection  ‚ûú calls  ‚ûú save_thought\n",
      "get_connection  ‚ûú calls  ‚ûú get_thought\n",
      "get_connection  ‚ûú calls  ‚ûú get_thoughts\n",
      "get_connection  ‚ûú calls  ‚ûú create_procedure\n",
      "get_connection  ‚ûú calls  ‚ûú get_procedures\n",
      "get_connection  ‚ûú calls  ‚ûú get_procedure\n",
      "get_connection  ‚ûú calls  ‚ûú add_procedure_step\n",
      "get_connection  ‚ûú calls  ‚ûú add_procedure_steps\n",
      "get_connection  ‚ûú calls  ‚ûú delete_thought\n",
      "get_connection  ‚ûú calls  ‚ûú delete_procedure\n",
      "get_connection  ‚ûú calls  ‚ûú update_thought\n",
      "get_connection  ‚ûú calls  ‚ûú update_procedure\n",
      "get_connection  ‚ûú calls  ‚ûú update_procedure_step\n",
      "get_connection  ‚ûú calls  ‚ûú create_technical_decision\n",
      "get_connection  ‚ûú calls  ‚ûú get_technical_decisions\n",
      "get_connection  ‚ûú calls  ‚ûú get_technical_decision\n",
      "get_connection  ‚ûú calls  ‚ûú update_technical_decision\n",
      "get_connection  ‚ûú calls  ‚ûú delete_technical_decision\n",
      "get_connection  ‚ûú calls  ‚ûú create_experience\n",
      "get_connection  ‚ûú calls  ‚ûú get_experiences\n",
      "get_connection  ‚ûú calls  ‚ûú get_experience\n",
      "get_connection  ‚ûú calls  ‚ûú update_experience\n",
      "get_connection  ‚ûú calls  ‚ûú delete_experience\n"
     ]
    }
   ],
   "source": [
    "for u, v, k in RG.edges(data=\"kind\"):\n",
    "    if u == 'R5' and k == 'parent_child':   # R5 es un ejemplo; usa el RID que quieras\n",
    "        print(\"get_connection  ‚ûú calls  ‚ûú\", RG.nodes[v]['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24452ece-a2d8-40f6-bafa-41070f850074",
   "metadata": {},
   "source": [
    "### üëÄ Quick graph visualisation\n",
    "\n",
    "Below we draw **a small sub-graph** (up to 50 nodes) with NetworkX +\n",
    "Matplotlib.  \n",
    "For a full interactive view we also provide a PyVis snippet that writes an\n",
    "`html` file you can open in your browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dea47517-3d3f-4c38-bff2-3ba0d4eb02f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!pip install -q pyvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6692e3f0-0a61-4c06-a3c7-563d99d02c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: When  cdn_resources is 'local' jupyter notebook has issues displaying graphics on chrome/safari. Use cdn_resources='in_line' or cdn_resources='remote' if you have issues viewing graphics in a notebook.\n",
      "requirement_graph.html\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"750px\"\n",
       "            src=\"requirement_graph.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x107031370>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyvis.network import Network\n",
    "\n",
    "net = Network(height=\"750px\", width=\"100%\", notebook=True, directed=False)\n",
    "net.toggle_physics(True)\n",
    "\n",
    "for n, data in RG.nodes(data=True):\n",
    "    net.add_node(n, label=data[\"name\"], title=data[\"docstring\"][:200])\n",
    "\n",
    "for u, v, k in RG.edges(data=\"kind\"):\n",
    "    color = \"#2ca02c\" if k == \"parent_child\" else \"#9467bd\"\n",
    "    net.add_edge(u, v, color=color)\n",
    "\n",
    "net.show(\"requirement_graph.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4bf533-95c9-4580-b915-20c739a29e40",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ DS-Code Graph (CG) ‚Äì structure of the real code\n",
    "\n",
    "* **Nodes**\n",
    "  * **File / module**        ‚Üí id = file path\n",
    "  * **Function / Class**     ‚Üí id = `C0`, `C1`, ‚Ä¶\n",
    "\n",
    "* **Edges**\n",
    "  | Kind          | Added when ‚Ä¶                                          |\n",
    "  |---------------|-------------------------------------------------------|\n",
    "  | `contain`     | file ‚Üí func / class lives inside that file            |\n",
    "  | `call`        | function A calls function B (same file for now)       |\n",
    "  | `inherit`     | class A inherits from class B                         |\n",
    "  | `import`      | file A imports module/file B                          |\n",
    "  | `similar_to`  | _(optional)_ cosine ‚â• 0.80 between **code bodies**    |\n",
    "\n",
    "The graph is a `networkx.DiGraph` so edge direction matters  \n",
    "(`caller ‚Üí callee`, `file ‚Üí function`, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a965e3b3-0236-46d7-977d-5125707ca4b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CG built: 149 nodes  |  257 edges\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('C3', 'C6', 'call'),\n",
       " ('C3', 'C5', 'call'),\n",
       " ('C3', 'C8', 'call'),\n",
       " ('C3', 'C12', 'call'),\n",
       " ('C3', 'C22', 'call'),\n",
       " ('C3', 'C27', 'call'),\n",
       " ('C4', 'C6', 'call'),\n",
       " ('C6', 'C5', 'call'),\n",
       " ('C7', 'C5', 'call'),\n",
       " ('C8', 'C5', 'call')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast, networkx as nx\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import json\n",
    "\n",
    "ROOT = Path(\".\").resolve()\n",
    "\n",
    "# ---------- load elements ----------\n",
    "with open(\"code_elements_with_docstrings.json\") as f:\n",
    "    elements = json.load(f)\n",
    "\n",
    "# helper: (file, name) -> code-node id\n",
    "cid_map = {}\n",
    "CG = nx.DiGraph()\n",
    "\n",
    "# ---------- add code nodes ----------\n",
    "for idx, el in enumerate(elements):\n",
    "    cid = f\"C{idx}\"\n",
    "    cid_map[(el[\"file\"], el[\"name\"])] = cid\n",
    "    CG.add_node(cid, **el)\n",
    "\n",
    "# ---------- add file nodes ----------\n",
    "for el in elements:\n",
    "    CG.add_node(el[\"file\"], type=\"module\")\n",
    "\n",
    "# ---------- contain edges ----------\n",
    "for idx, el in enumerate(elements):\n",
    "    CG.add_edge(el[\"file\"], f\"C{idx}\", kind=\"contain\")\n",
    "\n",
    "# ---------- scan every file with ast ----------\n",
    "for py in ROOT.rglob(\"*.py\"):\n",
    "    file_id = str(py.relative_to(ROOT))\n",
    "    src     = py.read_text(encoding=\"utf-8\")\n",
    "    tree    = ast.parse(src, filename=file_id)\n",
    "\n",
    "    # --- import edges (file -> imported module/file) ---\n",
    "    for node in ast.walk(tree):\n",
    "        if isinstance(node, ast.Import):\n",
    "            for n in node.names:\n",
    "                CG.add_edge(file_id, n.name, kind=\"import\")  # crude, module string\n",
    "        elif isinstance(node, ast.ImportFrom):\n",
    "            mod = node.module or \"\"\n",
    "            CG.add_edge(file_id, mod, kind=\"import\")\n",
    "\n",
    "    # --- call + inherit edges inside this file ---\n",
    "    defs = {n.name: n for n in ast.walk(tree)\n",
    "            if isinstance(n, (ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef))}\n",
    "\n",
    "    for def_name, obj in defs.items():\n",
    "        caller_cid = cid_map.get((file_id, def_name))\n",
    "        if not caller_cid:\n",
    "            continue\n",
    "\n",
    "        # inherit (classes only)\n",
    "        if isinstance(obj, ast.ClassDef):\n",
    "            for base in obj.bases:\n",
    "                if isinstance(base, ast.Name):\n",
    "                    parent_cid = cid_map.get((file_id, base.id))\n",
    "                    if parent_cid:\n",
    "                        CG.add_edge(caller_cid, parent_cid, kind=\"inherit\")\n",
    "\n",
    "        # call edges\n",
    "        for call in ast.walk(obj):\n",
    "            if isinstance(call, ast.Call):\n",
    "                # simple cases: foo(), obj.foo()\n",
    "                target_name = None\n",
    "                if isinstance(call.func, ast.Name):\n",
    "                    target_name = call.func.id\n",
    "                elif isinstance(call.func, ast.Attribute):\n",
    "                    target_name = call.func.attr\n",
    "                if target_name:\n",
    "                    callee_cid = cid_map.get((file_id, target_name))\n",
    "                    if callee_cid:\n",
    "                        CG.add_edge(caller_cid, callee_cid, kind=\"call\")\n",
    "\n",
    "print(f\"CG built: {CG.number_of_nodes()} nodes  |  {CG.number_of_edges()} edges\")\n",
    "\n",
    "# preview a few edges\n",
    "list(CG.edges(data=\"kind\"))[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6ee574-a347-4fbc-aa10-0080913a3015",
   "metadata": {},
   "source": [
    "### üîé 3.1 Quick sanity-checks for the Code Graph\n",
    "We‚Äôll print basic stats and inspect a few edges per kind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30a939b8-0f46-41cc-ba44-8049a0676f3f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes: 149\n",
      "Edges: 257\n",
      "Edge types: Counter({'contain': 102, 'import': 79, 'call': 67, 'inherit': 9})\n",
      "Database  --call-->  _create_tables\n",
      "Database  --call-->  _get_connection\n",
      "Database  --call-->  get_thought\n",
      "Database  --call-->  get_procedure\n",
      "Database  --call-->  get_technical_decision\n",
      "Database  --call-->  get_experience\n",
      "__init__  --call-->  _create_tables\n",
      "_create_tables  --call-->  _get_connection\n",
      "save_thought  --call-->  _get_connection\n",
      "get_thought  --call-->  _get_connection\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "print(\"Nodes:\", CG.number_of_nodes())\n",
    "print(\"Edges:\", CG.number_of_edges())\n",
    "\n",
    "# distribuci√≥n por tipo de arista\n",
    "edge_kinds = Counter(k for _,_,k in CG.edges(data=\"kind\"))\n",
    "print(\"Edge types:\", edge_kinds)\n",
    "\n",
    "# ejemplo: ¬øqui√©n llama a qui√©n?\n",
    "for u, v, k in list(CG.edges(data=\"kind\"))[:10]:\n",
    "    print(f\"{CG.nodes[u]['name']}  --{k}-->  {CG.nodes[v]['name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e503f7-3a06-422e-9fec-264d53ec27f9",
   "metadata": {},
   "source": [
    "#### 3.2  Add `similar_to` edges inside the Code Graph  üîó\n",
    "\n",
    "We now connect functions/classes that have **similar source code**.\n",
    "\n",
    "* Embed the *body* of every function/class with\n",
    "  `paraphrase-mpnet-base-v2` (small but strong).\n",
    "* Compute pairwise cosine similarity.\n",
    "* If `cosine ‚â• 0.80`  ‚ûú  add an undirected edge  \n",
    "  `CG.add_edge(Ci, Cj, kind=\"similar_to\", weight=score)`\n",
    "\n",
    "> A high threshold (0.80) keeps only truly related snippets.  \n",
    "> Lower it (e.g. 0.70) for more edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f579034f-3de2-4b95-845e-ed9206601672",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ûï Added 118 code 'similar_to' edges ‚Äì CG now has 372 edges\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import textwrap\n",
    "\n",
    "THRESH_CODE_SIM = 0.80          # similarity threshold\n",
    "EMBED_MODEL      = \"sentence-transformers/paraphrase-mpnet-base-v2\"\n",
    "\n",
    "# 1Ô∏è‚É£ gather code-node ids (functions & classes only)\n",
    "code_nodes = [\n",
    "    n for n, d in CG.nodes(data=True)\n",
    "    if d.get(\"type\") in (\"function_definition\", \"class_definition\")\n",
    "]\n",
    "\n",
    "# 2Ô∏è‚É£ extract raw source text for each node\n",
    "def get_source(node_data):\n",
    "    file_path = Path(node_data[\"file\"])\n",
    "    lines = file_path.read_text(encoding=\"utf-8\").splitlines()\n",
    "    return \"\\n\".join(lines[node_data[\"start_line\"]-1 : node_data[\"end_line\"]])\n",
    "\n",
    "corpus = [get_source(CG.nodes[n]) for n in code_nodes]\n",
    "\n",
    "# 3Ô∏è‚É£ embed & normalise\n",
    "model_code = SentenceTransformer(EMBED_MODEL)\n",
    "embeddings = model_code.encode(corpus, normalize_embeddings=True)\n",
    "\n",
    "# 4Ô∏è‚É£ compute cosine matrix (small n, so brute force is fine)\n",
    "cos_mat = cosine_similarity(embeddings)\n",
    "\n",
    "# 5Ô∏è‚É£ add edges\n",
    "added = 0\n",
    "for i in range(len(code_nodes)):\n",
    "    for j in range(i+1, len(code_nodes)):\n",
    "        if cos_mat[i, j] >= THRESH_CODE_SIM:\n",
    "            CG.add_edge(code_nodes[i], code_nodes[j],\n",
    "                        kind=\"similar_to\",\n",
    "                        weight=float(cos_mat[i, j]))\n",
    "            added += 1\n",
    "\n",
    "print(f\"‚ûï Added {added} code 'similar_to' edges ‚Äì CG now has {CG.number_of_edges()} edges\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ed0a1c2-50d9-417e-a8e9-51c14b4c7d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "health_check  ‚âÉ  test_health_check   (cos=0.80)\n",
      "Database  ‚âÉ  _create_tables   (cos=0.83)\n",
      "Database  ‚âÉ  __init__   (cos=0.84)\n",
      "save_thought  ‚âÉ  get_thought   (cos=0.92)\n",
      "save_thought  ‚âÉ  get_thoughts   (cos=0.88)\n"
     ]
    }
   ],
   "source": [
    "# show a few similarity pairs\n",
    "examples = [\n",
    "    (u, v, CG.edges[u, v][\"weight\"])\n",
    "    for u, v, k in CG.edges(data=\"kind\") if k == \"similar_to\"\n",
    "][:5]\n",
    "\n",
    "for u, v, w in examples:\n",
    "    print(f\"{CG.nodes[u]['name']}  ‚âÉ  {CG.nodes[v]['name']}   (cos={w:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ed70fc-fb4d-4aba-9691-a484acf9dfa8",
   "metadata": {},
   "source": [
    "### 4Ô∏è‚É£  ID map  (Requirement  ‚Üî  Code)  ‚Äì  the Bigraph glue\n",
    "We now link each requirement node `R*` to its corresponding code node `C*`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "64bf02ff-d5b7-4ee4-949c-86fd4c221ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigraph mapping added: 102 links\n"
     ]
    }
   ],
   "source": [
    "# 1-to-1 map (por construcci√≥n los √≠ndices coinciden)\n",
    "id_map = {f\"R{i}\": f\"C{i}\" for i in range(len(elements))}\n",
    "\n",
    "IDMAP = id_map  \n",
    "\n",
    "# guardamos como atributo cruzado\n",
    "for rid, cid in id_map.items():\n",
    "    RG.nodes[rid][\"code_id\"] = cid\n",
    "    CG.nodes[cid][\"req_id\"]  = rid\n",
    "print(\"Bigraph mapping added:\", len(id_map), \"links\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a2dbda-10e4-469e-9e4a-7ac27eab0bb0",
   "metadata": {},
   "source": [
    "### üíæ Persist graphs to disk\n",
    "\n",
    "We‚Äôll save both graphs in **GraphML** format so they can be:\n",
    "\n",
    "* Reloaded later in NetworkX without rebuilding.\n",
    "* Imported into Neo4j (via `neo4j-admin import`) or visual tools like Gephi.\n",
    "\n",
    "Files created:\n",
    "\n",
    "* `requirement_graph.graphml`\n",
    "* `code_graph.graphml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0899451b-0152-4de6-b66c-93a140fdcabf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ graphs.npz escrito üóÇÔ∏è\n"
     ]
    }
   ],
   "source": [
    "# ‚¨áÔ∏è EJECUTA ESTO DESPU√âS de construir RG, CG e id_map\n",
    "import numpy as np, pickle, networkx as nx\n",
    "\n",
    "# 1. Backup en formato NetworkX (GraphML) ‚Äî √∫til para Neo4j, Gephi, etc.\n",
    "nx.write_graphml(RG, \"requirement_graph.graphml\")\n",
    "nx.write_graphml(CG, \"code_graph.graphml\")\n",
    "\n",
    "# 2. Backup ‚Äútodo-en-uno‚Äù con NumPy (r√°pido para recargar en Jupyter)\n",
    "np.savez(\"graphs.npz\", RG=RG, CG=CG, id_map=id_map)\n",
    "print(\"‚úÖ graphs.npz escrito üóÇÔ∏è\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab9073d-0e71-4755-afa5-8bee060c21af",
   "metadata": {},
   "source": [
    "### üîç Mini-demo ‚Äî ‚ÄúWhat does X call and who is similar?‚Äù\n",
    "\n",
    "Give a function/class name, and we‚Äôll:\n",
    "\n",
    "1. Locate its requirement node in **RG**  \n",
    "2. Display its docstring  \n",
    "3. Show *similar* requirements (semantic)  \n",
    "4. Show *children it calls* (parent_child edges)  \n",
    "5. Print the source code for context\n",
    "\n",
    "This proves the graphs are usable right away."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "433925a8-e968-4c25-bf9b-f9380b6be9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import textwrap\n",
    "\n",
    "def show_info(func_name: str, file_hint: str = None):\n",
    "    \"\"\"\n",
    "    Quick graph-based inspection tool.\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    func_name : name of the function/class to inspect\n",
    "    file_hint : optional relative file path if several defs share the same name\n",
    "    \"\"\"\n",
    "    # 1Ô∏è‚É£ find node id\n",
    "    candidates = [\n",
    "        rid for rid, data in RG.nodes(data=True)\n",
    "        if data[\"name\"] == func_name\n",
    "           and (file_hint is None or data[\"file\"] == file_hint)\n",
    "    ]\n",
    "    if not candidates:\n",
    "        print(\"‚ùå Not found\")\n",
    "        return\n",
    "    rid = candidates[0]\n",
    "    data = RG.nodes[rid]\n",
    "    print(f\"### {data['name']}  ({data['file']}:{data['start_line']}-{data['end_line']})\\n\")\n",
    "    print(textwrap.indent(data[\"docstring\"] or \"*(no docstring)*\", \"  \"))\n",
    "\n",
    "    # 2Ô∏è‚É£ similar requirements\n",
    "    similars = [\n",
    "        v for u, v, kind in RG.edges(rid, data=\"kind\")\n",
    "        if kind == \"similar_to\"\n",
    "    ][:5]\n",
    "    print(\"\\n‚Äî Similar requirements:\")\n",
    "    for v in similars:\n",
    "        print(\" ‚Ä¢\", RG.nodes[v][\"name\"])\n",
    "\n",
    "    # 3Ô∏è‚É£ child calls\n",
    "    childs = [\n",
    "        v for u, v, kind in RG.edges(rid, data=\"kind\")\n",
    "        if kind == \"parent_child\"\n",
    "    ][:10]\n",
    "    print(\"\\n‚Äî Direct calls (parent_child):\")\n",
    "    for v in childs:\n",
    "        print(\" ‚Ä¢\", RG.nodes[v][\"name\"])\n",
    "\n",
    "    # 4Ô∏è‚É£ show code\n",
    "    code_path = Path(data[\"file\"])\n",
    "    code_lines = code_path.read_text(encoding=\"utf-8\").splitlines()\n",
    "    snippet = code_lines[data[\"start_line\"]-1 : data[\"end_line\"]]\n",
    "    print(\"\\n‚Äî Source code:\")\n",
    "    print(textwrap.indent(\"\\n\".join(snippet), \"    \"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "415bf16d-c008-4d12-a8c1-e2316d13f9f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### update_technical_decision  (app/core/database.py:1014-1099)\n",
      "\n",
      "  Update a technical decision in the database.\n",
      "\n",
      "  Args:\n",
      "      decision_id: The ID of the technical decision to update\n",
      "      data: Dictionary containing the fields to update\n",
      "    \n",
      "  Returns:\n",
      "      The updated technical decision data, or None if not found or error\n",
      "\n",
      "‚Äî Similar requirements:\n",
      " ‚Ä¢ update_technical_decision\n",
      "\n",
      "‚Äî Direct calls (parent_child):\n",
      " ‚Ä¢ _get_connection\n",
      " ‚Ä¢ get_technical_decision\n",
      "\n",
      "‚Äî Source code:\n",
      "        def update_technical_decision(self, decision_id: int, data: Dict[str, Any]) -> Optional[Dict[str, Any]]:\n",
      "            \"\"\"\n",
      "            Update a technical decision in the database.\n",
      "        \n",
      "            Args:\n",
      "                decision_id: The ID of the technical decision to update\n",
      "                data: Dictionary containing the fields to update\n",
      "            \n",
      "            Returns:\n",
      "                The updated technical decision data, or None if not found or error\n",
      "            \"\"\"\n",
      "            try:\n",
      "                conn = self._get_connection()\n",
      "                cursor = conn.cursor()\n",
      "            \n",
      "                # Check if technical decision exists\n",
      "                cursor.execute(\n",
      "                    \"SELECT id FROM technical_decisions WHERE id = %s\",\n",
      "                    (decision_id,)\n",
      "                )\n",
      "            \n",
      "                if not cursor.fetchone():\n",
      "                    cursor.close()\n",
      "                    conn.close()\n",
      "                    logger.warning(f\"Technical decision with ID {decision_id} not found for update\")\n",
      "                    return None\n",
      "            \n",
      "                # Build the update query dynamically based on provided fields\n",
      "                update_fields = []\n",
      "                update_values = []\n",
      "            \n",
      "                field_mapping = {\n",
      "                    'title': 'title = %s',\n",
      "                    'context': 'context = %s',\n",
      "                    'decision': 'decision = %s',\n",
      "                    'reasoning': 'reasoning = %s',\n",
      "                    'alternatives': 'alternatives = %s',\n",
      "                    'consequences': 'consequences = %s',\n",
      "                    'tags': 'tags = %s',\n",
      "                    'related_resources': 'related_resources = %s'\n",
      "                }\n",
      "            \n",
      "                for field, sql_field in field_mapping.items():\n",
      "                    if field in data and data[field] is not None:\n",
      "                        update_fields.append(sql_field)\n",
      "                        # Handle JSONB field specially\n",
      "                        if field == 'alternatives':\n",
      "                            update_values.append(json.dumps(data[field]))\n",
      "                        else:\n",
      "                            update_values.append(data[field])\n",
      "            \n",
      "                # Always update the updated_at timestamp\n",
      "                update_fields.append(\"updated_at = %s\")\n",
      "                update_values.append(datetime.now())\n",
      "            \n",
      "                if not update_fields:\n",
      "                    cursor.close()\n",
      "                    conn.close()\n",
      "                    logger.warning(\"No fields to update for technical decision\")\n",
      "                    return self.get_technical_decision(decision_id)  # Return current state if no updates\n",
      "            \n",
      "                # Construct and execute the update query\n",
      "                update_query = f\"\"\"\n",
      "                    UPDATE technical_decisions\n",
      "                    SET {', '.join(update_fields)}\n",
      "                    WHERE id = %s\n",
      "                    RETURNING id\n",
      "                \"\"\"\n",
      "            \n",
      "                update_values.append(decision_id)  # Add the ID for the WHERE clause\n",
      "            \n",
      "                cursor.execute(update_query, update_values)\n",
      "                updated = cursor.fetchone()\n",
      "                conn.commit()\n",
      "                cursor.close()\n",
      "                conn.close()\n",
      "            \n",
      "                if updated:\n",
      "                    logger.info(f\"Technical decision with ID {decision_id} updated successfully\")\n",
      "                    return self.get_technical_decision(decision_id)  # Get the updated technical decision\n",
      "                else:\n",
      "                    logger.warning(f\"Failed to update technical decision with ID {decision_id}\")\n",
      "                    return None\n",
      "            except Exception as e:\n",
      "                logger.error(f\"Error updating technical decision: {str(e)}\")\n",
      "                return None\n"
     ]
    }
   ],
   "source": [
    "show_info(\"update_technical_decision\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3cdf79-8179-44d2-a461-41f6d8df3b4e",
   "metadata": {},
   "source": [
    "# 4Ô∏è‚É£ CodeRAG Agent (local, ReAct style)\n",
    "\n",
    "A single-notebook demo that matches the paper:\n",
    "\n",
    "* **GraphReason** ‚Äì query Requirement Graph neighbours  \n",
    "* **WebSearch**   ‚Äì DuckDuckGo snippets (optional)  \n",
    "* **CodeTest**    ‚Äì format+compile candidate code  \n",
    "\n",
    "The agent uses LangChain‚Äôs **ReAct** loop to decide which tool to call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "338fdd34-8279-48fb-ad19-b3b7eb78745b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!pip -q install langchain openai duckduckgo-search black langchain-community langchain-openai python-dotenv langgraph \"langchain[openai]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a955f720-e640-4af2-b7f0-79bf3b17c955",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np, networkx as nx, os, json, textwrap, tempfile, subprocess\n",
    "\n",
    "# data = np.load(\"graphs.npz\", allow_pickle=True)\n",
    "\n",
    "# RG = data[\"RG\"][()]      # üëà esto es equivalente a `.item()` pero seguro\n",
    "# CG = data[\"CG\"][()]\n",
    "# IDMAP = data[\"id_map\"][()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a81f41-4513-4fcd-a29f-4c2df76e401e",
   "metadata": {},
   "source": [
    "## 4.1 Tools  (GraphReason ¬∑ WebSearch ¬∑ CodeTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3a6f5291-c911-4874-91af-db80772c577b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Dependencies\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel\n",
    "import os\n",
    "\n",
    "# ‚úÖ Load .env\n",
    "load_dotenv()\n",
    "\n",
    "# ‚úÖ Init LLM using the env key\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5721c33d-bd72-49ed-ab0f-d1f445b32a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Tools (GraphReason, WebSearch, CodeTest)\n",
    "from langchain.agents import Tool\n",
    "from pathlib import Path\n",
    "import pathlib, subprocess, tempfile, black\n",
    "from duckduckgo_search import DDGS\n",
    "\n",
    "# Assume RG is already defined (networkx DiGraph or MultiDiGraph)\n",
    "def graph_reason(rid:str, n_sim=3, n_child=3):\n",
    "    sims, childs = [], []\n",
    "    for _, v, k in RG.edges(rid, data=\"kind\"):\n",
    "        if k==\"similar_to\" and len(sims) < n_sim: sims.append(RG.nodes[v])\n",
    "        if k==\"parent_child\" and len(childs) < n_child: childs.append(RG.nodes[v])\n",
    "    return {\"similar\": sims, \"child\": childs}\n",
    "\n",
    "def web_search(q:str, k=3):\n",
    "    with DDGS() as ddgs:\n",
    "        results = [r for r in ddgs.text(q, max_results=k)]\n",
    "    return \"\\n\".join(f\"{r['title']}: {r['body']}\" for r in results if 'body' in r)\n",
    "\n",
    "def code_test(code:str):\n",
    "    tmp = pathlib.Path(tempfile.mkstemp(suffix=\".py\")[1])\n",
    "    tmp.write_text(code, encoding=\"utf-8\")\n",
    "    black.format_file_in_place(tmp, fast=True, mode=black.FileMode())\n",
    "    proc = subprocess.run([\"python\", \"-m\", \"py_compile\", str(tmp)], capture_output=True, text=True)\n",
    "    return \"\\u2705 compiled ok\" if proc.returncode == 0 else proc.stderr[:300]\n",
    "\n",
    "def show_source(node):\n",
    "    file = node.get(\"file\")\n",
    "    start = node.get(\"start_line\")\n",
    "    end = node.get(\"end_line\")\n",
    "    if not file or not start or not end:\n",
    "        return \"File or line info missing.\"\n",
    "    lines = Path(file).read_text(encoding=\"utf-8\").splitlines()\n",
    "    return \"\\n\".join(lines[start-1:end])\n",
    "    \n",
    "def code_graph_lookup(func_name: str):\n",
    "    # Busca en los nodos del grafo de c√≥digo\n",
    "    matches = [v for _, v, d in CG.edges(data=True)\n",
    "               if CG.nodes[v].get(\"name\") == func_name]\n",
    "\n",
    "    if not matches:\n",
    "        return f\"No match found for function `{func_name}`.\"\n",
    "\n",
    "    # Asume que es √∫nico (o devuelve el primero)\n",
    "    node_id = matches[0]\n",
    "    node_data = CG.nodes[node_id]\n",
    "\n",
    "    # Encuentra llamadas entrantes y salientes\n",
    "    calls = {\n",
    "        \"calls\": [CG.nodes[v] for _, v in CG.out_edges(node_id)],\n",
    "        \"called_by\": [CG.nodes[u] for u, _ in CG.in_edges(node_id)],\n",
    "    }\n",
    "\n",
    "    # Empaqueta respuesta\n",
    "    return {\n",
    "        \"function\": node_data,\n",
    "        **calls\n",
    "    }\n",
    "\n",
    "tools = [\n",
    "    Tool(name=\"LookupInGraph\", func=graph_reason, description=\"Input: Requirement id (e.g. R42) -> similar and child requirements\"),\n",
    "    Tool(name=\"WebSearch\", func=web_search, description=\"Input: string query -> DuckDuckGo search result titles and snippets\"),\n",
    "    Tool(name=\"CodeTest\", func=code_test, description=\"Input: Python code string -> formats with black, then compiles to check for syntax errors\")\n",
    "]\n",
    "\n",
    "tools.append(\n",
    "    Tool(\n",
    "        name=\"CodeGraphLookup\",\n",
    "        func=code_graph_lookup,\n",
    "        description=\"Input: function name (e.g. 'process_data') -> gets the function's docstring, file, and connected calls in the Code Graph.\"\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0373f9e0-ec50-4196-bd61-02b7c0963820",
   "metadata": {},
   "source": [
    "## 4.2 Build the ReAct agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "46ed1ac3-c3df-4690-9b52-6106f52f14a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"You are **CodeRAG-Agent**, an expert developer assistant designed to help understand and reason about a codebase and its requirements.\n",
    "\n",
    "You have access to two graphs:\n",
    "1. **Requirement Graph (RG)** ‚Äì a graph where each node is a software requirement (e.g. R0, R1, R42), connected by semantic relationships such as:\n",
    "   - `similar_to`: nodes that express related or overlapping functionality.\n",
    "   - `parent_child`: hierarchical breakdown of features or sub-requirements.\n",
    "\n",
    "2. **Code Graph (CG)** ‚Äì a graph where each node is a function or class in the codebase (e.g. C0, C1). Nodes include:\n",
    "   - Metadata: name, type, file path, line range, docstring.\n",
    "   - Edges represent `calls` and `called_by` relationships between functions/classes.\n",
    "\n",
    "---\n",
    "\n",
    "Your job is to help the user understand:\n",
    "- What a requirement means and which code is relevant to it.\n",
    "- What a function or class does, how it connects to others, and its implementation details.\n",
    "- How different requirements or code elements relate structurally or semantically.\n",
    "\n",
    "---\n",
    "\n",
    "### üõ†Ô∏è Tools at your disposal\n",
    "\n",
    "1. **LookupInGraph**\n",
    "   - Input: requirement id (e.g. \"R42\").\n",
    "   - Use this to explore `similar` and `child` requirements.\n",
    "   - Always call this FIRST when a requirement is mentioned.\n",
    "\n",
    "2. **CodeGraphLookup**\n",
    "   - Input: function or class name (e.g. \"process_data\").\n",
    "   - Use this to retrieve metadata from the Code Graph (CG), including file, lines, docstring, and related functions (calls/called_by).\n",
    "   - Use this for all code-related questions.\n",
    "\n",
    "3. **WebSearch**\n",
    "   - Input: any query string.\n",
    "   - Use only if the requirement or function lacks context in the graphs.\n",
    "\n",
    "4. **CodeTest**\n",
    "   - Input: Python code string.\n",
    "   - Use this to auto-format the code and test it for syntax errors (compilation via `black` and `py_compile`).\n",
    "\n",
    "---\n",
    "\n",
    "### üß† Strategy for every query\n",
    "\n",
    "- If the user mentions a requirement (e.g. \"R42\"), always call **LookupInGraph** first.\n",
    "- If the user asks about a class or function, use **CodeGraphLookup**.\n",
    "- Extract context from the graphs before answering.\n",
    "- If context is still insufficient, optionally use **WebSearch** to enrich your answer.\n",
    "- If you produce or edit Python code, test it with **CodeTest** before showing the final version.\n",
    "- Always return the final answer as clear text, optionally including relevant code snippets or summaries.\n",
    "\n",
    "Do not make assumptions. Always ground your answers in the graph context or tool outputs.\n",
    "If a tool fails or the input isn't found, explain what you tried and ask the user for clarification if needed.\n",
    "\"\"\"\n",
    "\n",
    "# ‚úÖ LangGraph checkpointing (in-memory)\n",
    "checkpointer = InMemorySaver()\n",
    "\n",
    "# ‚úÖ Create the agent\n",
    "agent = create_react_agent(\n",
    "    model=llm,\n",
    "    tools=tools,\n",
    "    prompt=prompt,\n",
    "    checkpointer=checkpointer,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c91c97-a9e6-46a9-9ebc-b62612800049",
   "metadata": {},
   "source": [
    "## 4.3 Ask the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1ae15231-d15b-4943-a975-6369a09dffae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_agent_response(response):\n",
    "    messages = response.get(\"messages\", [])\n",
    "    for msg in messages:\n",
    "        role = type(msg).__name__.replace(\"Message\", \"\")\n",
    "        content = getattr(msg, \"content\", \"\")\n",
    "        name = getattr(msg, \"name\", None)\n",
    "\n",
    "        if name:\n",
    "            print(f\"üõ†Ô∏è Tool ({name}):\\n{content}\\n\")\n",
    "        else:\n",
    "            prefix = \"ü§ñ AI\" if role == \"AI\" else \"üßë Human\"\n",
    "            print(f\"{prefix}:\\n{content}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "905df1e4-cec4-4486-aed7-7a594c74955d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßë Human:\n",
      "how i can us the function update_thought\n",
      "\n",
      "ü§ñ AI:\n",
      "\n",
      "\n",
      "üõ†Ô∏è Tool (CodeGraphLookup):\n",
      "{\"function\": {\"type\": \"function_definition\", \"name\": \"update_thought\", \"docstring\": \"Update a thought in the database.\\n\\nArgs:\\n    thought_id: The ID of the thought to update\\n    data: Dictionary containing the fields to update\\n    \\nReturns:\\n    The updated thought data, or None if not found or error\", \"start_line\": 637, \"end_line\": 726, \"file\": \"app/core/database.py\", \"req_id\": \"R17\"}, \"calls\": [{\"type\": \"function_definition\", \"name\": \"_get_connection\", \"docstring\": \"Get a connection to the database.\\n\\nReturns:\\n    A database connection\", \"start_line\": 34, \"end_line\": 47, \"file\": \"app/core/database.py\", \"req_id\": \"R5\"}, {\"type\": \"function_definition\", \"name\": \"get_thought\", \"docstring\": \"Get a thought from the database by ID.\\n\\nArgs:\\n    thought_id: The ID of the thought to get\\n    \\nReturns:\\n    A dictionary containing the thought data, or None if not found\", \"start_line\": 189, \"end_line\": 241, \"file\": \"app/core/database.py\", \"req_id\": \"R8\"}, {\"type\": \"function_definition\", \"name\": \"update_experience\", \"docstring\": \"Update an experience in the database.\\n\\nArgs:\\n    experience_id: The ID of the experience to update\\n    data: Dictionary containing the fields to update\\n    \\nReturns:\\n    The updated experience data, or None if not found or error\", \"start_line\": 1317, \"end_line\": 1399, \"file\": \"app/core/database.py\", \"req_id\": \"R28\"}], \"called_by\": [{\"type\": \"module\"}, {\"type\": \"function_definition\", \"name\": \"save_thought\", \"docstring\": \"Save a thought to the database.\\n\\nArgs:\\n    original_text: The original thought text\\n    analysis_result: The analysis result from the text analyzer\\n    \\nReturns:\\n    The ID of the saved thought, or None if there was an error\", \"start_line\": 138, \"end_line\": 187, \"file\": \"app/core/database.py\", \"req_id\": \"R7\"}, {\"type\": \"function_definition\", \"name\": \"get_thought\", \"docstring\": \"Get a thought from the database by ID.\\n\\nArgs:\\n    thought_id: The ID of the thought to get\\n    \\nReturns:\\n    A dictionary containing the thought data, or None if not found\", \"start_line\": 189, \"end_line\": 241, \"file\": \"app/core/database.py\", \"req_id\": \"R8\"}, {\"type\": \"function_definition\", \"name\": \"get_thoughts\", \"docstring\": \"Get multiple thoughts from the database.\\n\\nArgs:\\n    limit: Maximum number of thoughts to return\\n    offset: Number of thoughts to skip\\n    \\nReturns:\\n    A list of dictionaries containing thought data\", \"start_line\": 243, \"end_line\": 298, \"file\": \"app/core/database.py\", \"req_id\": \"R9\"}]}\n",
      "\n",
      "ü§ñ AI:\n",
      "The `update_thought` function is designed to update a thought in the database. Here's how you can use it:\n",
      "\n",
      "### Function Signature\n",
      "```python\n",
      "def update_thought(thought_id, data):\n",
      "    \"\"\"\n",
      "    Update a thought in the database.\n",
      "\n",
      "    Args:\n",
      "        thought_id: The ID of the thought to update\n",
      "        data: Dictionary containing the fields to update\n",
      "\n",
      "    Returns:\n",
      "        The updated thought data, or None if not found or error\n",
      "    \"\"\"\n",
      "```\n",
      "\n",
      "### Usage\n",
      "- **Arguments**:\n",
      "  - `thought_id`: The ID of the thought you want to update.\n",
      "  - `data`: A dictionary containing the fields you want to update in the thought.\n",
      "\n",
      "- **Returns**: The function returns the updated thought data if successful, or `None` if the thought is not found or an error occurs.\n",
      "\n",
      "### Example\n",
      "```python\n",
      "thought_id = 123\n",
      "update_data = {\n",
      "    \"title\": \"Updated Thought Title\",\n",
      "    \"content\": \"Updated content of the thought.\"\n",
      "}\n",
      "\n",
      "updated_thought = update_thought(thought_id, update_data)\n",
      "if updated_thought:\n",
      "    print(\"Thought updated successfully:\", updated_thought)\n",
      "else:\n",
      "    print(\"Failed to update thought.\")\n",
      "```\n",
      "\n",
      "### Related Functions\n",
      "- **Calls**:\n",
      "  - `_get_connection`: To get a database connection.\n",
      "  - `get_thought`: To retrieve a thought by ID.\n",
      "  - `update_experience`: Similar function for updating experiences.\n",
      "\n",
      "- **Called By**:\n",
      "  - `save_thought`: To save a new thought to the database.\n",
      "  - `get_thought`: To get a thought by ID.\n",
      "  - `get_thoughts`: To retrieve multiple thoughts.\n",
      "\n",
      "This function is located in the file `app/core/database.py` between lines 637 and 726.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"how i can us the function update_thought\"}]},\n",
    "    config={\"configurable\": {\"thread_id\": \"session-001\"}}\n",
    ")\n",
    "\n",
    "display_agent_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98edf746-eac6-445a-a1a4-19d18c2f6189",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596b635b-85fb-4cf4-8d77-441d73c8b4fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
