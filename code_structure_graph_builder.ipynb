{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d8a1721-02df-4e79-b9b7-083bc43afa30",
   "metadata": {},
   "source": [
    "# üß† GPT now understands my repo like a senior dev ‚Äì here's how\n",
    "\n",
    "This notebook is an end-to-end reproduction and reinterpretation of the **CodeRAG** framework (see [paper](https://arxiv.org/pdf/2504.10046)), adapted to run locally on your own codebase.\n",
    "\n",
    "We want to give GPT (or any LLM) the ability to:\n",
    "- Parse and **understand your entire repo**\n",
    "- Retrieve and reason over related code\n",
    "- Answer questions like a senior developer would ‚Äî with **zero fine-tuning**\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Goal of this experiment\n",
    "\n",
    "Our objective is to build a **code-aware assistant** using a combination of:\n",
    "\n",
    "- üîç **Tree-sitter** to parse and structure the codebase\n",
    "- üß† **LLMs** to describe each function or class (aka \"requirements\")\n",
    "- üï∏Ô∏è **Code graphs** to represent dependencies (calls, imports, etc)\n",
    "- üß≠ **Agentic reasoning** to let the LLM query and retrieve context dynamically\n",
    "- ‚ö° **RAG (Retrieval-Augmented Generation)** to reduce hallucinations and give smarter answers\n",
    "\n",
    "The end result is a local-first, fully transparent, and extensible RAG pipeline tailored for your own project.\n",
    "\n",
    "---\n",
    "\n",
    "## üß™ Inspired by CodeRAG (What we're replicating)\n",
    "\n",
    "From the CodeRAG paper (April 2025), we aim to recreate the following innovations:\n",
    "\n",
    "1. **Requirement Graph**  \n",
    "   A graph where each node is a *natural language description* of a function or class. Edges represent semantic similarity or parent-child relations.\n",
    "\n",
    "2. **DS-Code Graph**  \n",
    "   A code graph that encodes structural dependencies like:\n",
    "   - function calls\n",
    "   - class inheritance\n",
    "   - file/module containment\n",
    "   - semantic similarity (via embeddings)\n",
    "\n",
    "3. **BiGraph Mapping**  \n",
    "   Links between requirements and code elements ‚Äî allowing retrieval of relevant code given a high-level prompt.\n",
    "\n",
    "4. **Agentic Reasoning**  \n",
    "   An LLM-driven reasoning loop that dynamically:\n",
    "   - queries the graph\n",
    "   - follows dependencies\n",
    "   - does web search if needed\n",
    "   - formats and tests generated code\n",
    "\n",
    "---\n",
    "\n",
    "## ü™ú Pipeline Overview (what this notebook covers)\n",
    "\n",
    "| Step | Description |\n",
    "|------|-------------|\n",
    "| ‚úÖ 1. Parse your local repo using Tree-sitter |\n",
    "| ‚úÖ 2. Extract all functions and classes |\n",
    "| ‚úÖ 3. Generate descriptions for each (via LLM) |\n",
    "| ‚úÖ 4. Build the **Requirement Graph** |\n",
    "| ‚úÖ 5. Build the **DS-Code Graph** |\n",
    "| ‚úÖ 6. Link both graphs into a BiGraph |\n",
    "| ‚úÖ 7. Implement a simple **agentic loop** using ReAct |\n",
    "| ‚úÖ 8. Let GPT answer deep questions about your code (with full context) |\n",
    "\n",
    "---\n",
    "\n",
    "## üß∞ Tech Stack\n",
    "\n",
    "| Component        | Tool                            |\n",
    "|------------------|---------------------------------|\n",
    "| Parsing          | `tree-sitter-language-pack`     |\n",
    "| Description gen. | OpenAI / DeepSeek-V2.5          |\n",
    "| Graph storage    | Neo4j                           |\n",
    "| Semantic sim.    | HuggingFace Transformers        |\n",
    "| Reasoning agent  | Custom ReAct (or LangChain)     |\n",
    "| Validation       | `black`, `pytest`, `mypy`       |\n",
    "\n",
    "---\n",
    "\n",
    "## üîó References & Credits\n",
    "\n",
    "- [CodeRAG: Supportive Code Retrieval on Bigraph for Real-World Code Generation](https://arxiv.org/pdf/2504.10046)\n",
    "- [Self-RAG (Asai et al., 2023)](https://arxiv.org/pdf/2307.05068)\n",
    "- [DRAGIN: Dynamic RAG for real-time needs](https://arxiv.org/pdf/2501.13742)\n",
    "- [CodeRAG benchmark (June 2024)](https://arxiv.org/pdf/2406.14497)\n",
    "\n",
    "---\n",
    "\n",
    "üëâ Let‚Äôs get started by parsing the repo with Tree-sitter..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bbbf10-7219-41aa-ab35-ae06a06fb5f8",
   "metadata": {},
   "source": [
    "## üì¶ Install dependencies\n",
    "\n",
    "We‚Äôll begin by installing the `tree-sitter-language-pack` Python library, which provides precompiled Tree-sitter grammars for popular languages ‚Äî including Python.\n",
    "\n",
    "This saves us from having to manually clone grammars or compile `.so` libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5baed20f-b420-4afd-87a2-819ed4bf6c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tree-sitter-language-pack\n",
      "  Downloading tree_sitter_language_pack-0.8.0-cp39-abi3-macosx_10_13_universal2.whl.metadata (17 kB)\n",
      "Requirement already satisfied: tree-sitter>=0.23.2 in /opt/anaconda3/lib/python3.12/site-packages (from tree-sitter-language-pack) (0.24.0)\n",
      "Collecting tree-sitter-c-sharp>=0.23.1 (from tree-sitter-language-pack)\n",
      "  Downloading tree_sitter_c_sharp-0.23.1-cp39-abi3-macosx_11_0_arm64.whl.metadata (2.7 kB)\n",
      "Collecting tree-sitter-embedded-template>=0.23.2 (from tree-sitter-language-pack)\n",
      "  Downloading tree_sitter_embedded_template-0.23.2-cp39-abi3-macosx_11_0_arm64.whl.metadata (2.2 kB)\n",
      "Collecting tree-sitter-yaml>=0.7.0 (from tree-sitter-language-pack)\n",
      "  Downloading tree_sitter_yaml-0.7.1-cp310-abi3-macosx_11_0_arm64.whl.metadata (1.8 kB)\n",
      "Downloading tree_sitter_language_pack-0.8.0-cp39-abi3-macosx_10_13_universal2.whl (28.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m28.6/28.6 MB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading tree_sitter_c_sharp-0.23.1-cp39-abi3-macosx_11_0_arm64.whl (419 kB)\n",
      "Downloading tree_sitter_embedded_template-0.23.2-cp39-abi3-macosx_11_0_arm64.whl (10 kB)\n",
      "Downloading tree_sitter_yaml-0.7.1-cp310-abi3-macosx_11_0_arm64.whl (45 kB)\n",
      "Installing collected packages: tree-sitter-yaml, tree-sitter-embedded-template, tree-sitter-c-sharp, tree-sitter-language-pack\n",
      "Successfully installed tree-sitter-c-sharp-0.23.1 tree-sitter-embedded-template-0.23.2 tree-sitter-language-pack-0.8.0 tree-sitter-yaml-0.7.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tree-sitter-language-pack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55627cc9-16a1-4989-8851-c739c9586824",
   "metadata": {},
   "source": [
    "## üß™ Parse a test string with Tree-sitter\n",
    "\n",
    "Let's load the Python parser and run Tree-sitter on a simple test snippet to confirm everything is working.\n",
    "\n",
    "We also define a small `dump()` helper function to pretty-print the AST (abstract syntax tree) node structure.\n",
    "\n",
    "This will help us verify that Tree-sitter is correctly parsing the function and its components (name, parameters, body, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a213375-9fa7-48bc-be27-0683df2f6027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module: def foo(): pass\n",
      "  function_definition: def foo(): pass\n",
      "    identifier: foo\n",
      "    parameters: ()\n",
      "    block: pass\n",
      "      pass_statement: pass\n"
     ]
    }
   ],
   "source": [
    "from tree_sitter_language_pack import get_parser\n",
    "\n",
    "parser = get_parser(\"python\")\n",
    "tree = parser.parse(b\"def foo(): pass\")\n",
    "\n",
    "def dump(node, indent=0):\n",
    "    print(\"  \" * indent + f\"{node.type}: {node.text.decode('utf-8')}\")\n",
    "    for child in node.named_children:\n",
    "        dump(child, indent + 1)\n",
    "\n",
    "root = parser.parse(b\"def foo(): pass\").root_node\n",
    "dump(root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1934e129-9a69-4bd9-bbea-91e73a1261f7",
   "metadata": {},
   "source": [
    "## üìÇ Parse all Python files in the repo\n",
    "\n",
    "Now that Tree-sitter is working, let‚Äôs walk through the entire local repo and extract all `function_definition` and `class_definition` nodes.\n",
    "\n",
    "For each one, we‚Äôll collect:\n",
    "\n",
    "- Type (`function` or `class`)\n",
    "- Name\n",
    "- Start and end line\n",
    "- File path\n",
    "\n",
    "This structured data will help us build the code graph later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e543255f-8a51-48eb-9f8a-aa9cd536129d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>start_line</th>\n",
       "      <th>end_line</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>class_definition</td>\n",
       "      <td>Build</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>tree-sitter-python/setup.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>function_definition</td>\n",
       "      <td>run</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>tree-sitter-python/setup.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>class_definition</td>\n",
       "      <td>BdistWheel</td>\n",
       "      <td>17</td>\n",
       "      <td>22</td>\n",
       "      <td>tree-sitter-python/setup.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>function_definition</td>\n",
       "      <td>get_tag</td>\n",
       "      <td>18</td>\n",
       "      <td>22</td>\n",
       "      <td>tree-sitter-python/setup.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>class_definition</td>\n",
       "      <td>TokenTests</td>\n",
       "      <td>17</td>\n",
       "      <td>80</td>\n",
       "      <td>tree-sitter-python/examples/python2-grammar-cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>class_definition</td>\n",
       "      <td>TestLanguage</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>tree-sitter-python/bindings/python/tests/test_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>function_definition</td>\n",
       "      <td>test_can_load_grammar</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>tree-sitter-python/bindings/python/tests/test_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>function_definition</td>\n",
       "      <td>_get_query</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>tree-sitter-python/bindings/python/tree_sitter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>function_definition</td>\n",
       "      <td>__getattr__</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>tree-sitter-python/bindings/python/tree_sitter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>function_definition</td>\n",
       "      <td>__dir__</td>\n",
       "      <td>30</td>\n",
       "      <td>34</td>\n",
       "      <td>tree-sitter-python/bindings/python/tree_sitter...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>657 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    type                   name  start_line  end_line  \\\n",
       "0       class_definition                  Build           9        14   \n",
       "1    function_definition                    run          10        14   \n",
       "2       class_definition             BdistWheel          17        22   \n",
       "3    function_definition                get_tag          18        22   \n",
       "4       class_definition             TokenTests          17        80   \n",
       "..                   ...                    ...         ...       ...   \n",
       "652     class_definition           TestLanguage           6        11   \n",
       "653  function_definition  test_can_load_grammar           7        11   \n",
       "654  function_definition             _get_query           8        11   \n",
       "655  function_definition            __getattr__          14        20   \n",
       "656  function_definition                __dir__          30        34   \n",
       "\n",
       "                                                  file  \n",
       "0                          tree-sitter-python/setup.py  \n",
       "1                          tree-sitter-python/setup.py  \n",
       "2                          tree-sitter-python/setup.py  \n",
       "3                          tree-sitter-python/setup.py  \n",
       "4    tree-sitter-python/examples/python2-grammar-cr...  \n",
       "..                                                 ...  \n",
       "652  tree-sitter-python/bindings/python/tests/test_...  \n",
       "653  tree-sitter-python/bindings/python/tests/test_...  \n",
       "654  tree-sitter-python/bindings/python/tree_sitter...  \n",
       "655  tree-sitter-python/bindings/python/tree_sitter...  \n",
       "656  tree-sitter-python/bindings/python/tree_sitter...  \n",
       "\n",
       "[657 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tree_sitter_language_pack import get_parser\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# Setup\n",
    "parser = get_parser(\"python\")\n",
    "REPO_ROOT = Path(\".\").resolve()\n",
    "\n",
    "# Extract function/class nodes\n",
    "def extract_code_elements(source_code: str, file_path: str):\n",
    "    tree = parser.parse(bytes(source_code, \"utf-8\"))\n",
    "    root = tree.root_node\n",
    "    elements = []\n",
    "\n",
    "    def visit(node):\n",
    "        if node.type in (\"function_definition\", \"class_definition\"):\n",
    "            name_node = node.child_by_field_name(\"name\")\n",
    "            name = name_node.text.decode(\"utf-8\") if name_node else \"<anonymous>\"\n",
    "            elements.append({\n",
    "                \"type\": node.type,\n",
    "                \"name\": name,\n",
    "                \"start_line\": node.start_point[0] + 1,\n",
    "                \"end_line\": node.end_point[0] + 1,\n",
    "                \"file\": str(file_path)\n",
    "            })\n",
    "        for child in node.named_children:\n",
    "            visit(child)\n",
    "\n",
    "    visit(root)\n",
    "    return elements\n",
    "\n",
    "# Walk through repo\n",
    "all_elements = []\n",
    "for py_file in REPO_ROOT.rglob(\"*.py\"):\n",
    "    try:\n",
    "        code = py_file.read_text(encoding=\"utf-8\")\n",
    "        extracted = extract_code_elements(code, py_file.relative_to(REPO_ROOT))\n",
    "        all_elements.extend(extracted)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Failed to parse {py_file}: {e}\")\n",
    "\n",
    "# Save results\n",
    "with open(\"code_elements.json\", \"w\") as f:\n",
    "    json.dump(all_elements, f, indent=2)\n",
    "\n",
    "# Preview results\n",
    "import pandas as pd\n",
    "pd.DataFrame(all_elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56dd4ee-d962-4858-8615-434882ef0bbb",
   "metadata": {},
   "source": [
    "## üßæ Requirement Descriptions (Docstrings)\n",
    "\n",
    "In this project, we assume that each function and class in the codebase already includes a properly written **docstring** that describes its purpose, inputs, and outputs.\n",
    "\n",
    "This serves as the \"requirement\" we need for building the **Requirement Graph** in the next step.\n",
    "\n",
    "> ‚ö†Ô∏è If the codebase lacks docstrings or uses inconsistent formatting, you would need to generate these descriptions using a language model (e.g. GPT-4 or DeepSeek) based on the raw source code.\n",
    "\n",
    "Since our current dataset is clean and well-documented, we‚Äôll skip this step and move directly to extracting docstrings from the parsed code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1dfa11-916a-4a4a-93d2-4ad041ee552e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
